{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12847512,"sourceType":"datasetVersion","datasetId":8125875},{"sourceId":12848144,"sourceType":"datasetVersion","datasetId":8126291},{"sourceId":12856964,"sourceType":"datasetVersion","datasetId":8132137}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Project Overview (Unknown Language Translation to English)\n\n| üîπ Term        | Definition                                                                 |\n|----------------|---------------------------------------------------------------------------|\n| **LLM**        | AI model trained on massive text data to understand, generate, and translate human-like language. |\n| **Transformer**| Neural architecture using self-attention to model sequences efficiently; backbone of modern LLMs. |\n| **T5 Small**   | Lightweight Transformer-based Seq2Seq model for text tasks; pretrained on English, limited resources. |\n\n\n### üöÄ Seq2Seq T5 Model ‚Äì Purposeful Challenges & Customization\n\n1. **üìÇ Data Preparation**  \n   - Generated **Train, Test, Val** separately from Grok, ChatGPT, Gemini.  \n   - Three categories:  \n     1Ô∏è‚É£ Mixed Bangla-English in English  \n     2Ô∏è‚É£ Pure Bangla in Bangla words  \n     3Ô∏è‚É£ Mixed Bangla-English (English in English Letter and Bangla in Bangla Letter)  \n   - **Limited dataset**, no external Bangla text included.  \n   - **üéØ Target column**: English translation ‚Äì purpose: teach the new language to translate into English.\n\n2. **‚öôÔ∏è Model Selection**  \n   - **T5 Small** chosen for resource constraints.  \n   - Model is **unaware of Bangla**.  \n\n3. **üìù Vocabulary & Tokenization**  \n   - Extract vocab only from **generated Train & Val data**.  \n   - Combine **T5 English tokens + new Bangla tokens**.  \n   - Use **SentencePiece** for uniform tokenization.  \n\n4. **üîß T5 Configuration Changes**  \n   - Increase **dropout & attention_dropout** for stability.  \n   - Add **extra encoder & decoder layers** for capacity.  \n   - Freeze base layers to preserve English knowledge.  \n\n5. **üß© Custom Layers / Blocks**  \n   - **Adapter Layers**: lightweight residual blocks for parameter-efficient fine-tuning.  \n   - **LoRA**: low-rank matrices on Q/K/V to inject Bangla patterns.  \n   - **Adaptive Attention**: gating between decoder & encoder states.  \n\n6. **‚ö° Optimizer & Scheduler**  \n   - Use **Adafactor** with automatic **relative step LR** and **warmup**.  \n\n7. **üìä Performance Evaluation**  \n   - **BLEU**: n-gram overlap (translation accuracy)  \n   - **ROUGE-L**: longest common subsequence (fluency)  \n   - **Perplexity / Log-Likelihood**: model confidence & prediction probability  \n   - **Validation monitoring** with early stopping to prevent overfitting.  \n","metadata":{}},{"cell_type":"markdown","source":"# üì¶ Import Libraries","metadata":{}},{"cell_type":"code","source":"# ============================\n# Core Libraries\n# ============================\n!pip install transformers torch         # HuggingFace Transformers + PyTorch\n\n#=============================\n# Dynamic Learning Rate Finder\n#=============================\n!pip install torch-lr-finder\n\n# ============================\n# Evaluation Metrics\n# ============================\n!pip install rouge-score                # ROUGE scoring\n!pip install evaluate                   # HuggingFace evaluate library\n!pip install sacrebleu                  # BLEU scoring backend\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T16:52:32.419189Z","iopub.execute_input":"2025-08-25T16:52:32.419434Z","iopub.status.idle":"2025-08-25T16:54:03.584594Z","shell.execute_reply.started":"2025-08-25T16:52:32.419410Z","shell.execute_reply":"2025-08-25T16:54:03.583515Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m104.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nCollecting torch-lr-finder\n  Downloading torch_lr_finder-0.2.2-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from torch-lr-finder) (3.7.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-lr-finder) (1.26.4)\nRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from torch-lr-finder) (2.6.0+cu124)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-lr-finder) (4.67.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from torch-lr-finder) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->torch-lr-finder) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->torch-lr-finder) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->torch-lr-finder) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->torch-lr-finder) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->torch-lr-finder) (2025.5.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->torch-lr-finder) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->torch-lr-finder) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->torch-lr-finder) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->torch-lr-finder) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->torch-lr-finder) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->torch-lr-finder) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->torch-lr-finder) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->torch-lr-finder) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->torch-lr-finder) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->torch-lr-finder) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->torch-lr-finder) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->torch-lr-finder) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->torch-lr-finder) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->torch-lr-finder) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->torch-lr-finder) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=0.4.1->torch-lr-finder) (1.3.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->torch-lr-finder) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->torch-lr-finder) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->torch-lr-finder) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->torch-lr-finder) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->torch-lr-finder) (11.2.1)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->torch-lr-finder) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->torch-lr-finder) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch-lr-finder) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch-lr-finder) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch-lr-finder) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch-lr-finder) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch-lr-finder) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch-lr-finder) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->torch-lr-finder) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=0.4.1->torch-lr-finder) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-lr-finder) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-lr-finder) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch-lr-finder) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch-lr-finder) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch-lr-finder) (2024.2.0)\nDownloading torch_lr_finder-0.2.2-py3-none-any.whl (12 kB)\nInstalling collected packages: torch-lr-finder\nSuccessfully installed torch-lr-finder-0.2.2\nCollecting rouge-score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (8.2.1)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.5.1)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (2024.11.6)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge-score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge-score) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rouge-score) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rouge-score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rouge-score) (2024.2.0)\nBuilding wheels for collected packages: rouge-score\n  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=73e35dba846ea4a0ef689aa0bd9ac3b1329eeec2d005c16dfcac464086cfe6df\n  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\nSuccessfully built rouge-score\nInstalling collected packages: rouge-score\nSuccessfully installed rouge-score-0.1.2\nCollecting evaluate\n  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.4)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.5.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.33.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nCollecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.13)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.6.15)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec, evaluate\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.5.1\n    Uninstalling fsspec-2025.5.1:\n      Successfully uninstalled fsspec-2025.5.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.5 fsspec-2025.3.0\nCollecting sacrebleu\n  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting portalocker (from sacrebleu)\n  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (1.26.4)\nRequirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->sacrebleu) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\nInstalling collected packages: portalocker, sacrebleu\nSuccessfully installed portalocker-3.2.0 sacrebleu-2.5.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"\n- T5 (Text-to-Text Transfer Transformer)\n- Encoder-Decoder Architecture: The Encoder processes the input sequence, and the Decoder generates output sequence\n","metadata":{}},{"cell_type":"code","source":"# ============================\n# Environment & OS\n# ============================\nimport os\nimport shutil\nimport time\n\n# ============================\n# Core Libraries\n# ============================\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\n# ============================\n# PyTorch: Core & Utilities\n# ============================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda.amp import autocast, GradScaler        # Mixed precision training\nfrom torchsummary import summary\n\n# ============================\n# Transformers / NLP\n# ============================\nfrom transformers import (\n    AutoTokenizer, T5ForConditionalGeneration, T5Config, T5Tokenizer,\n    get_linear_schedule_with_warmup\n)\nfrom transformers.models.t5.modeling_t5 import T5Block\n\n# ============================\n# Optimizer & Learning Rate Utilities\n# ============================\nfrom torch_lr_finder import LRFinder\nfrom torch.optim.lr_scheduler import LambdaLR\nimport torch.optim as optim\nfrom transformers import Adafactor\n\n# ============================\n# Evaluation Metrics\n# ============================\nfrom nltk.translate.bleu_score import corpus_bleu, sentence_bleu, SmoothingFunction\nfrom rouge_score import rouge_scorer\nfrom evaluate import load\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T17:12:40.858791Z","iopub.execute_input":"2025-08-25T17:12:40.859111Z","iopub.status.idle":"2025-08-25T17:12:40.865496Z","shell.execute_reply.started":"2025-08-25T17:12:40.859090Z","shell.execute_reply":"2025-08-25T17:12:40.864642Z"}},"outputs":[],"execution_count":45},{"cell_type":"markdown","source":"# üìÇ Load Datasets (Train and Val)","metadata":{}},{"cell_type":"code","source":"# === Train Dataset ===\ntraining_dataset = pd.read_csv(\"/kaggle/input/bangla-english-custom-dataset/final-datasets/train-data.csv\")\nprint(\"=================About Training Dataset======================\")\nprint(f\"shape of dataset: {training_dataset.shape}\")\ntraining_dataset.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T16:54:54.486127Z","iopub.execute_input":"2025-08-25T16:54:54.486726Z","iopub.status.idle":"2025-08-25T16:54:54.628292Z","shell.execute_reply.started":"2025-08-25T16:54:54.486700Z","shell.execute_reply":"2025-08-25T16:54:54.627573Z"}},"outputs":[{"name":"stdout","text":"=================About Training Dataset======================\nshape of dataset: (4008, 2)\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                                Text  \\\n0  Apni kemon achhen ajke? Ami chinta korchilam a...   \n1  Apni recently kemon feel korchen? Ami chinta k...   \n2  Apni ki ajke kichu emotional feel korchen? Ami...   \n3  Apni ki recently kono boro decision niyechhen?...   \n4  Apni ki recently kichu kichu stress feel korch...   \n\n                                              Target  \n0  How are you today? I was thinking whether you ...  \n1  How have you been feeling lately? I was thinki...  \n2  Are you feeling emotional today? I was thinkin...  \n3  Have you recently made any big decision? I was...  \n4  Have you recently felt some stress? I was thin...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Apni kemon achhen ajke? Ami chinta korchilam a...</td>\n      <td>How are you today? I was thinking whether you ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Apni recently kemon feel korchen? Ami chinta k...</td>\n      <td>How have you been feeling lately? I was thinki...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Apni ki ajke kichu emotional feel korchen? Ami...</td>\n      <td>Are you feeling emotional today? I was thinkin...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Apni ki recently kono boro decision niyechhen?...</td>\n      <td>Have you recently made any big decision? I was...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Apni ki recently kichu kichu stress feel korch...</td>\n      <td>Have you recently felt some stress? I was thin...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# === Validation Dataset ===\nvalid_dataset = pd.read_csv(\"/kaggle/input/bangla-english-custom-dataset/final-datasets/val-data.csv\")\n\nprint(\"=================About Validation Dataset======================\")\n\nprint(f\"shape of dataset: {valid_dataset.shape}\")\nvalid_dataset.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T16:54:54.629051Z","iopub.execute_input":"2025-08-25T16:54:54.629333Z","iopub.status.idle":"2025-08-25T16:54:54.667811Z","shell.execute_reply.started":"2025-08-25T16:54:54.629315Z","shell.execute_reply":"2025-08-25T16:54:54.667171Z"}},"outputs":[{"name":"stdout","text":"=================About Validation Dataset======================\nshape of dataset: (945, 2)\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                Text  \\\n0  Apnar kotha shune amar khub shanti lage. Kichu...   \n1  Apni ajker jonno ki plan korechhen? Jodi time ...   \n2  Ajke office e khub pressure chhilo. Apni ki kh...   \n3  Ajke onek rush chhilo rastay. Apni ki safe e b...   \n4  Apnar shathe kotha bole amar mon ektu halka ho...   \n\n                                              Target  \n0  Listening to you gives me peace. I was a bit s...  \n1  What plans do you have for today? If you have ...  \n2  There was a lot of pressure at the office toda...  \n3  The roads were very rushed today. Did you retu...  \n4  Talking with you makes my mind lighter. I try ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Apnar kotha shune amar khub shanti lage. Kichu...</td>\n      <td>Listening to you gives me peace. I was a bit s...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Apni ajker jonno ki plan korechhen? Jodi time ...</td>\n      <td>What plans do you have for today? If you have ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Ajke office e khub pressure chhilo. Apni ki kh...</td>\n      <td>There was a lot of pressure at the office toda...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Ajke onek rush chhilo rastay. Apni ki safe e b...</td>\n      <td>The roads were very rushed today. Did you retu...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Apnar shathe kotha bole amar mon ektu halka ho...</td>\n      <td>Talking with you makes my mind lighter. I try ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"# üßΩ Download Model to Perform Offline Work","metadata":{}},{"cell_type":"code","source":"model_name = \"t5-small\"\n\n# The path to your saved tokenizer files\nlocal_path = f\"./{model_name}-tokenizer\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T16:55:01.280590Z","iopub.execute_input":"2025-08-25T16:55:01.281151Z","iopub.status.idle":"2025-08-25T16:55:01.285490Z","shell.execute_reply.started":"2025-08-25T16:55:01.281117Z","shell.execute_reply":"2025-08-25T16:55:01.284762Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# download and load model and tokenizer\ntokenizer=AutoTokenizer.from_pretrained(model_name)\nmodel = T5ForConditionalGeneration.from_pretrained(model_name)\n\n# Save them to a specific local directory\ntokenizer.save_pretrained(local_path)\nmodel.save_pretrained(local_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T16:55:03.788432Z","iopub.execute_input":"2025-08-25T16:55:03.789227Z","iopub.status.idle":"2025-08-25T16:55:08.370893Z","shell.execute_reply.started":"2025-08-25T16:55:03.789193Z","shell.execute_reply":"2025-08-25T16:55:08.370095Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6c0981d172c481aac78e7027b46671d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45473441b8254efc92aed245024280b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33bb8461ab7947b699cf803c91d3a666"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62e4304bdd4a4e11815869ef6ea465d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5798676a4f1e487db00cc1a071a1b7de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f756567d09824693b4837aec9629f8f3"}},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"# ü§ñ Load Model","metadata":{}},{"cell_type":"code","source":"#Local directory\nlocal_directory = f\"./{model_name}-tokenizer\"\n\n#load tokenizer and model from local directory\n\ntokenizer = AutoTokenizer.from_pretrained(local_directory)\nmodel = T5ForConditionalGeneration.from_pretrained(local_directory)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T16:55:12.765302Z","iopub.execute_input":"2025-08-25T16:55:12.765582Z","iopub.status.idle":"2025-08-25T16:55:12.926380Z","shell.execute_reply.started":"2025-08-25T16:55:12.765558Z","shell.execute_reply":"2025-08-25T16:55:12.925607Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Print the desired attributes from tokenizer\nprint(f\"T5TokenizerFast(name_or_path='{tokenizer.name_or_path}', \\n\"\n      f\"vocab_size={tokenizer.vocab_size}, \\n\"\n      f\"model_max_length={tokenizer.model_max_length}, \\n\"\n      f\"is_fast={tokenizer.is_fast}, \\n\"\n      f\"padding_side='{tokenizer.padding_side}', \\n\"\n      f\"truncation_side='{tokenizer.truncation_side}')\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T16:55:17.599635Z","iopub.execute_input":"2025-08-25T16:55:17.599940Z","iopub.status.idle":"2025-08-25T16:55:17.604519Z","shell.execute_reply.started":"2025-08-25T16:55:17.599915Z","shell.execute_reply":"2025-08-25T16:55:17.603806Z"}},"outputs":[{"name":"stdout","text":"T5TokenizerFast(name_or_path='./t5-small-tokenizer', \nvocab_size=32100, \nmodel_max_length=512, \nis_fast=True, \npadding_side='right', \ntruncation_side='right')\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"| Component                     | Configuration / Notes                                                                 |\n|--------------------------------|-------------------------------------------------------------------------------------|\n| Embedding                     | `Embedding(32128, 512)`                                                             |\n| FFN size                       | 2048                                                                                |\n| Encoder / Decoder blocks       | 6 encoder + 6 decoder blocks                                                        |\n| Relative Attention Bias        | `Embedding(num_buckets, num_heads)`                                                |\n| Notes                          | üëâ More flexible than absolute positions; works well for long sequences and generalizes to unseen lengths |\n| Model Match                     | That matches **T5-Small**                                                          |\n","metadata":{}},{"cell_type":"code","source":"#model summary\n\nprint(f\"About Model: \\n {model}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T19:59:32.869536Z","iopub.execute_input":"2025-08-24T19:59:32.869802Z","iopub.status.idle":"2025-08-24T19:59:32.875264Z","shell.execute_reply.started":"2025-08-24T19:59:32.869780Z","shell.execute_reply":"2025-08-24T19:59:32.874592Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### üî• Encoder and Decoder Block","metadata":{}},{"cell_type":"code","source":"print(f\"Encoder Block: \\n{model.encoder.block[0]}\\n\\n\")\n\nprint(f\"Decoder Block: \\n{model.decoder.block[0]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T16:55:22.466510Z","iopub.execute_input":"2025-08-25T16:55:22.466775Z","iopub.status.idle":"2025-08-25T16:55:22.471728Z","shell.execute_reply.started":"2025-08-25T16:55:22.466756Z","shell.execute_reply":"2025-08-25T16:55:22.470930Z"}},"outputs":[{"name":"stdout","text":"Encoder Block: \nT5Block(\n  (layer): ModuleList(\n    (0): T5LayerSelfAttention(\n      (SelfAttention): T5Attention(\n        (q): Linear(in_features=512, out_features=512, bias=False)\n        (k): Linear(in_features=512, out_features=512, bias=False)\n        (v): Linear(in_features=512, out_features=512, bias=False)\n        (o): Linear(in_features=512, out_features=512, bias=False)\n        (relative_attention_bias): Embedding(32, 8)\n      )\n      (layer_norm): T5LayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (1): T5LayerFF(\n      (DenseReluDense): T5DenseActDense(\n        (wi): Linear(in_features=512, out_features=2048, bias=False)\n        (wo): Linear(in_features=2048, out_features=512, bias=False)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (act): ReLU()\n      )\n      (layer_norm): T5LayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n  )\n)\n\n\nDecoder Block: \nT5Block(\n  (layer): ModuleList(\n    (0): T5LayerSelfAttention(\n      (SelfAttention): T5Attention(\n        (q): Linear(in_features=512, out_features=512, bias=False)\n        (k): Linear(in_features=512, out_features=512, bias=False)\n        (v): Linear(in_features=512, out_features=512, bias=False)\n        (o): Linear(in_features=512, out_features=512, bias=False)\n        (relative_attention_bias): Embedding(32, 8)\n      )\n      (layer_norm): T5LayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (1): T5LayerCrossAttention(\n      (EncDecAttention): T5Attention(\n        (q): Linear(in_features=512, out_features=512, bias=False)\n        (k): Linear(in_features=512, out_features=512, bias=False)\n        (v): Linear(in_features=512, out_features=512, bias=False)\n        (o): Linear(in_features=512, out_features=512, bias=False)\n      )\n      (layer_norm): T5LayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (2): T5LayerFF(\n      (DenseReluDense): T5DenseActDense(\n        (wi): Linear(in_features=512, out_features=2048, bias=False)\n        (wo): Linear(in_features=2048, out_features=512, bias=False)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (act): ReLU()\n      )\n      (layer_norm): T5LayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n  )\n)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"print(f\"Details of Output layer of model: \\n{model.lm_head}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T16:55:28.768922Z","iopub.execute_input":"2025-08-25T16:55:28.769616Z","iopub.status.idle":"2025-08-25T16:55:28.773126Z","shell.execute_reply.started":"2025-08-25T16:55:28.769590Z","shell.execute_reply":"2025-08-25T16:55:28.772353Z"}},"outputs":[{"name":"stdout","text":"Details of Output layer of model: \nLinear(in_features=512, out_features=32128, bias=False)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"### ‚öôÔ∏è Change Model Config","metadata":{}},{"cell_type":"code","source":"# Load and customize config\nconfig = T5Config.from_pretrained('t5-small')\nconfig.dropout_rate = 0.3        # Default is 0.1\nconfig.attention_dropout_rate = 0.3  # Also increase attention dropout\n# Set LayerDrop value (e.g., 0.1 = 10% chance to drop each layer during training)\nconfig.layerdrop = 0.2 # Values like 0.1‚Äì0.2 are common starting points\n\n# Load model with modified config\nmodel = T5ForConditionalGeneration(config)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T16:56:32.820562Z","iopub.execute_input":"2025-08-25T16:56:32.820831Z","iopub.status.idle":"2025-08-25T16:56:33.924034Z","shell.execute_reply.started":"2025-08-25T16:56:32.820813Z","shell.execute_reply":"2025-08-25T16:56:33.923434Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"### üîßAdd Extra Encoder and Decoder Layer","metadata":{}},{"cell_type":"code","source":"# 1. Create new encoder block\nextra_encoder_block = T5Block(model.config, has_relative_attention_bias=False)\n\n# 2. Append to encoder stack\nmodel.encoder.block.append(extra_encoder_block)\n\n# 3. Create new decoder block\nextra_decoder_block = T5Block(model.config, has_relative_attention_bias=False)\n\n# 4. Append to decoder stack\nmodel.decoder.block.append(extra_decoder_block)\n\n# 5. Update config to reflect new layer counts\nmodel.config.num_layers += 1\nmodel.config.num_decoder_layers += 1\n\n# After appending new blocks\nmodel.config.num_layers = len(model.encoder.block)\nmodel.config.num_decoder_layers = len(model.decoder.block)\n\nprint(f\"Encoder layers: {len(model.encoder.block)}\")\nprint(f\"Decoder layers: {len(model.decoder.block)}\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T16:56:34.823402Z","iopub.execute_input":"2025-08-25T16:56:34.823664Z","iopub.status.idle":"2025-08-25T16:56:34.878049Z","shell.execute_reply.started":"2025-08-25T16:56:34.823643Z","shell.execute_reply":"2025-08-25T16:56:34.877515Z"}},"outputs":[{"name":"stdout","text":"Encoder layers: 7\nDecoder layers: 7\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# üèóÔ∏è Injecting New corpus","metadata":{}},{"cell_type":"code","source":"# custom_spm.model is enough (don't need custom_spm.vocab)\n#tokenizer = T5Tokenizer(vocab_file=\"/kaggle/input/corpus-and-tokenizer/custom_spm.model\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T07:28:40.502417Z","iopub.execute_input":"2025-08-24T07:28:40.502836Z","iopub.status.idle":"2025-08-24T07:28:40.516705Z","shell.execute_reply.started":"2025-08-24T07:28:40.502802Z","shell.execute_reply":"2025-08-24T07:28:40.516051Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üìå Sentence Tokenization Summary  \n\nüìë **Corpus Creation**  \nCollected and merged **4,953 rows** of Bangla-English text into a clean training corpus.  \n\n‚öôÔ∏è **Tokenizer Training**  \nTrained a **SentencePiece Unigram tokenizer** with **9,338 vocabulary size** and **99.95% character coverage**.  \n\nüìÇ **Output Files**  \nGenerated two key artifacts: **`custom_spm.model`** and **`custom_spm.vocab`**.  \n\nüöÄ **Usage**  \nThese files enable **consistent subword tokenization** for translation and text generation tasks.  \n\nüîó **Notebook**  \n[Bangla-English Tokenization on Kaggle](https://www.kaggle.com/code/shiblinomani/bangla-english-tokenization)  \n","metadata":{}},{"cell_type":"markdown","source":"### üéõÔ∏è Read Custom Vocab","metadata":{}},{"cell_type":"code","source":"# Purpose: Count the number of tokens in the custom SentencePiece vocab file.\ncustom_vocab_file = \"/kaggle/input/tokenized-words/custom_spm.vocab\"\n\nwith open(custom_vocab_file, \"r\", encoding=\"utf-8\") as f:\n    tokens = f.readlines()\n\nnum_tokens = len(tokens)\nprint(f\"Number of tokens in custom_spm.vocab: {num_tokens}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T16:56:41.451263Z","iopub.execute_input":"2025-08-25T16:56:41.451551Z","iopub.status.idle":"2025-08-25T16:56:41.465998Z","shell.execute_reply.started":"2025-08-25T16:56:41.451531Z","shell.execute_reply":"2025-08-25T16:56:41.465320Z"}},"outputs":[{"name":"stdout","text":"Number of tokens in custom_spm.vocab: 9338\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"### ‚úÇÔ∏è Append New and Unique Tokens (Avoid Duplicate)\n\n","metadata":{}},{"cell_type":"code","source":"# Purpose: Read custom vocab file, extract tokens not already in the tokenizer, \n# prepare a list of new tokens to add, and save them to a new file.\ncustom_tokens = []\n\nwith open(custom_vocab_file, \"r\", encoding=\"utf-8\") as f:\n    for line in f:\n        token = line.strip().split(\"\\t\")[0]  # token \\t score\n        if token not in tokenizer.get_vocab():  # avoid duplicates\n            custom_tokens.append(token)\n\nprint(f\"Number of new tokens to add: {len(custom_tokens)}\")\n\n# Save the new tokens to a file\nnew_tokens_file = \"new_custom_tokens.txt\"\nwith open(new_tokens_file, \"w\", encoding=\"utf-8\") as f:\n    for token in custom_tokens:\n        f.write(token + \"\\n\")\n\nprint(f\"New tokens saved to: {new_tokens_file}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T16:56:46.681146Z","iopub.execute_input":"2025-08-25T16:56:46.681906Z","iopub.status.idle":"2025-08-25T16:59:15.178786Z","shell.execute_reply.started":"2025-08-25T16:56:46.681847Z","shell.execute_reply":"2025-08-25T16:59:15.178017Z"}},"outputs":[{"name":"stdout","text":"Number of new tokens to add: 5680\nNew tokens saved to: new_custom_tokens.txt\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"### üß© Add new tokens with existing token","metadata":{}},{"cell_type":"code","source":"# Purpose: Add new custom tokens to the tokenizer and resize the model's token embeddings\n# to accommodate the expanded vocabulary.\ntokenizer.add_tokens(custom_tokens)\nmodel.resize_token_embeddings(len(tokenizer))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T16:59:22.885852Z","iopub.execute_input":"2025-08-25T16:59:22.886662Z","iopub.status.idle":"2025-08-25T16:59:23.964936Z","shell.execute_reply.started":"2025-08-25T16:59:22.886629Z","shell.execute_reply":"2025-08-25T16:59:23.964362Z"}},"outputs":[{"name":"stderr","text":"The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Embedding(37780, 512)"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"### üìè Save the model and tokenizer with Custom Vocab","metadata":{}},{"cell_type":"code","source":"#loacl path to save the token, model, config\nfile_path = \"./t5-small-custom-model\"\nos.makedirs(file_path, exist_ok=True)\n\n# Purpose: Save the tokenizer and model to the specified local directory\n# so they can be reloaded later for inf# Save tokenizer, model, and config\ntokenizer.save_pretrained(file_path)\nmodel.save_pretrained(file_path)\nmodel.config.save_pretrained(file_path)   # <- explicitly saves config.json\n\nprint(f\"Model, tokenizer, and config saved at: {file_path}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T17:00:20.814651Z","iopub.execute_input":"2025-08-25T17:00:20.815462Z","iopub.status.idle":"2025-08-25T17:00:21.600246Z","shell.execute_reply.started":"2025-08-25T17:00:20.815422Z","shell.execute_reply":"2025-08-25T17:00:21.599629Z"}},"outputs":[{"name":"stdout","text":"Model, tokenizer, and config saved at: ./t5-small-custom-model\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Move to working directory (optional)\n%cd /kaggle/working\n\n# Zip specific files/folders\n!zip -r t5_small_model_files.zip t5-small-custom-model new_custom_tokens.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T17:00:27.669940Z","iopub.execute_input":"2025-08-25T17:00:27.670652Z","iopub.status.idle":"2025-08-25T17:00:42.565104Z","shell.execute_reply.started":"2025-08-25T17:00:27.670618Z","shell.execute_reply":"2025-08-25T17:00:42.564145Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n  adding: t5-small-custom-model/ (stored 0%)\n  adding: t5-small-custom-model/tokenizer.json (deflated 81%)\n  adding: t5-small-custom-model/tokenizer_config.json (deflated 95%)\n  adding: t5-small-custom-model/config.json (deflated 63%)\n  adding: t5-small-custom-model/special_tokens_map.json (deflated 85%)\n  adding: t5-small-custom-model/added_tokens.json (deflated 72%)\n  adding: t5-small-custom-model/generation_config.json (deflated 29%)\n  adding: t5-small-custom-model/model.safetensors (deflated 7%)\n  adding: t5-small-custom-model/spiece.model (deflated 48%)\n  adding: new_custom_tokens.txt (deflated 64%)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"!ls -lh /kaggle/working/t5_small_model_files.zip\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T17:00:47.670357Z","iopub.execute_input":"2025-08-25T17:00:47.671259Z","iopub.status.idle":"2025-08-25T17:00:47.837792Z","shell.execute_reply.started":"2025-08-25T17:00:47.671211Z","shell.execute_reply":"2025-08-25T17:00:47.836886Z"}},"outputs":[{"name":"stdout","text":"-rw-r--r-- 1 root root 248M Aug 25 17:00 /kaggle/working/t5_small_model_files.zip\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Reload from local directory\ntokenizer = T5Tokenizer.from_pretrained(\"./t5-small-custom-model\")\nmodel = T5ForConditionalGeneration.from_pretrained(\"./t5-small-custom-model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T17:00:55.658315Z","iopub.execute_input":"2025-08-25T17:00:55.658678Z","iopub.status.idle":"2025-08-25T17:00:56.557935Z","shell.execute_reply.started":"2025-08-25T17:00:55.658646Z","shell.execute_reply":"2025-08-25T17:00:56.557202Z"}},"outputs":[{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\nSome weights of the model checkpoint at ./t5-small-custom-model were not used when initializing T5ForConditionalGeneration: ['decoder.block.6.layer.1.DenseReluDense.wi.weight', 'decoder.block.6.layer.1.DenseReluDense.wo.weight']\n- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of T5ForConditionalGeneration were not initialized from the model checkpoint at ./t5-small-custom-model and are newly initialized: ['decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.2.DenseReluDense.wi.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.2.layer_norm.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"### üèÉLoad the model and token with custom vocab ","metadata":{}},{"cell_type":"code","source":"#Local directory\n#local_directory = f\"./{model_name}-tokenizer\"\n\n#load tokenizer and model from local directory\n\n#tokenizer = AutoTokenizer.from_pretrained(local_directory)\n#model = T5ForConditionalGeneration.from_pretrained(local_directory)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T07:33:13.766923Z","iopub.execute_input":"2025-08-24T07:33:13.767358Z","iopub.status.idle":"2025-08-24T07:33:13.771257Z","shell.execute_reply.started":"2025-08-24T07:33:13.767336Z","shell.execute_reply":"2025-08-24T07:33:13.770448Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"tokenizer.vocab_size:\", tokenizer.vocab_size)  # ~32k (original)\nprint(\"len(tokenizer):\", len(tokenizer))              # 38,554 (merged)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T17:01:03.524515Z","iopub.execute_input":"2025-08-25T17:01:03.524802Z","iopub.status.idle":"2025-08-25T17:01:03.529951Z","shell.execute_reply.started":"2025-08-25T17:01:03.524781Z","shell.execute_reply":"2025-08-25T17:01:03.529121Z"}},"outputs":[{"name":"stdout","text":"tokenizer.vocab_size: 32000\nlen(tokenizer): 37780\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"<h3> üìù Note </h3>\n\n- üìÑ **custom_spm.vocab** ‚Üí 9,338 tokens (all tokens from your new-language corpus)  \n- üîπ **Original T5 tokenizer** ‚Üí 32,100 tokens  \n- ‚ûï **New tokens to add** ‚Üí 5,680  \n\n```python\nif token not in tokenizer.get_vocab():\n    custom_tokens.append(token)\n```\n    \n‚ö†Ô∏è Why only 12,186 tokens are added:\nThis only adds tokens that are NOT already in the T5 tokenizer.\nSome tokens from your 10,000 new-language tokens may already exist in T5‚Äôs vocab (English words, punctuation, or symbols).\n‚úÖ Therefore, only unique tokens that don‚Äôt collide with T5‚Äôs original 32.1k are added ‚Üí 5,680 in this case.\n\n**‚úÖ Now tokens are added to the current vocabulary of T5: `Embedding(37780, 512)`**\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"# üõ†Ô∏è Model Customization","metadata":{}},{"cell_type":"markdown","source":"| #   | Component     | Purpose / Role                                     | Importance                                                                                       |\n| --- | ------------- | -------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------- |\n| 1Ô∏è‚É£ | Embeddings    | Initial layer for input tokens                     | üõ°Ô∏è Preserve pretrained embeddings, reduce memory, ensure stability on small dataset                             |\n| 2Ô∏è‚É£ | Frozen Layers | Retain pretrained knowledge in lower layers        | ‚ö° Maintains generalization, prevents catastrophic forgetting, adapts efficiently to Bangla ‚Üí English translation |\n| 3Ô∏è‚É£ | Encoder       | Maps Bangla/Banglish input ‚Üí latent semantic space | ‚úÖ Preserve pretrained knowledge, adapt only higher layers to Bangla                                              |\n| 4Ô∏è‚É£ | Decoder       | Converts latent embeddings ‚Üí English output tokens | üéØ Learn mapping from Bangla latent space ‚Üí fluent English sequences                                             |\n| 5Ô∏è‚É£ | LM Head       | Generates final logits for output tokens           | ‚úçÔ∏è Required to produce correct English words corresponding to latent representation                              |\n","metadata":{}},{"cell_type":"markdown","source":"### Model config (after your edits)\n| Setting                      | Value                              | Purpose (plain English)                                  |\n|-----------------------------|------------------------------------|-----------------------------------------------------------|\n| Base model                  | t5-small                           | Start from strong pretrained weights                      |\n| Encoder layers              | 7 (6 + 1 extra)                    | Extra capacity to learn Bangla nuances                    |\n| Decoder layers              | 7 (6 + 1 extra)                    | Extra capacity for fluent, faithful English generation    |\n| dropout_rate                | 0.3 (‚Üë from 0.1)                   | Reduce overfitting; make representations more robust      |\n| attention_dropout_rate      | 0.3 (‚Üë from 0.1)                   | Regularize attention; prevent head over-reliance          |\n| layerdrop                   | 0.2                                | Randomly drop layers during training ‚Üí better generalization |\n| Relative attention bias     | First block only (unchanged)       | Stable positional inductive bias                          |\n| Extra blocks‚Äô rel. bias     | `has_relative_attention_bias=False`| Keep bias placement consistent with T5 design             |\n\n### Training plan (what to freeze vs train)\n| Part                       | Trainable? | Purpose (why this choice)                                       |\n|---------------------------|------------|------------------------------------------------------------------|\n| `model.shared` embedding  | ‚ùå Frozen   | Keep core token meanings stable across Bangla/English            |\n| Encoder layers 0‚Äì2        | ‚ùå Frozen   | Preserve general syntax/semantics from pretraining               |\n| Encoder layers 3‚Äì7        | ‚úÖ Train    | Adapt higher layers to Bangla grammar & context                  |\n| Decoder layers 0‚Äì7       | ‚úÖ Train    | Produce fluent, accurate English aligned to Bangla input         |\n| LM head (output layer)    | ‚úÖ Train    | Map decoder states ‚Üí target vocabulary effectively                |\n\n> Notes: layer indices are 0-based. With your added blocks, there are **7 encoder** and **7 decoder** layers total.\n","metadata":{}},{"cell_type":"markdown","source":"### üîí Freezing Parameters","metadata":{}},{"cell_type":"code","source":"# üîí Purpose: Freeze certain parameters of the T5 model for fine-tuning\ndef freeze_parameters(model, freeze_encoder_until_layer):\n    # 1. Freeze embeddings (shared input layer)\n    for param in model.shared.parameters():\n        param.requires_grad = False  # Embedding weights will not update\n\n    # 2. Freeze encoder layers up to index freeze_encoder_until_layer-1\n    # Example: freeze first 4 encoder layers ‚Üí (0,1,2,3)\n    for i, block in enumerate(model.encoder.block):\n        requires = i >= freeze_encoder_until_layer  \n        for p in block.parameters():\n            p.requires_grad = requires  \n\n    # 3. Unfreeze decoder fully\n    for p in model.decoder.parameters():\n        p.requires_grad = True  \n\n    # 4. Unfreeze lm_head (output layer)\n    for p in model.lm_head.parameters():\n        p.requires_grad = True  \n\n\n# ‚úÖ freeze embeddings + first 3 encoder layers\nfreeze_parameters(model, freeze_encoder_until_layer=3)\n\n# üîç Verify frozen parameters\nfor name, param in model.named_parameters():\n    if not param.requires_grad:\n        print(\"FROZEN:\", name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T17:01:12.989114Z","iopub.execute_input":"2025-08-25T17:01:12.989816Z","iopub.status.idle":"2025-08-25T17:01:12.997208Z","shell.execute_reply.started":"2025-08-25T17:01:12.989788Z","shell.execute_reply":"2025-08-25T17:01:12.996442Z"}},"outputs":[{"name":"stdout","text":"FROZEN: encoder.block.0.layer.0.SelfAttention.q.weight\nFROZEN: encoder.block.0.layer.0.SelfAttention.k.weight\nFROZEN: encoder.block.0.layer.0.SelfAttention.v.weight\nFROZEN: encoder.block.0.layer.0.SelfAttention.o.weight\nFROZEN: encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight\nFROZEN: encoder.block.0.layer.0.layer_norm.weight\nFROZEN: encoder.block.0.layer.1.DenseReluDense.wi.weight\nFROZEN: encoder.block.0.layer.1.DenseReluDense.wo.weight\nFROZEN: encoder.block.0.layer.1.layer_norm.weight\nFROZEN: encoder.block.1.layer.0.SelfAttention.q.weight\nFROZEN: encoder.block.1.layer.0.SelfAttention.k.weight\nFROZEN: encoder.block.1.layer.0.SelfAttention.v.weight\nFROZEN: encoder.block.1.layer.0.SelfAttention.o.weight\nFROZEN: encoder.block.1.layer.0.layer_norm.weight\nFROZEN: encoder.block.1.layer.1.DenseReluDense.wi.weight\nFROZEN: encoder.block.1.layer.1.DenseReluDense.wo.weight\nFROZEN: encoder.block.1.layer.1.layer_norm.weight\nFROZEN: encoder.block.2.layer.0.SelfAttention.q.weight\nFROZEN: encoder.block.2.layer.0.SelfAttention.k.weight\nFROZEN: encoder.block.2.layer.0.SelfAttention.v.weight\nFROZEN: encoder.block.2.layer.0.SelfAttention.o.weight\nFROZEN: encoder.block.2.layer.0.layer_norm.weight\nFROZEN: encoder.block.2.layer.1.DenseReluDense.wi.weight\nFROZEN: encoder.block.2.layer.1.DenseReluDense.wo.weight\nFROZEN: encoder.block.2.layer.1.layer_norm.weight\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"## üöÄ Updating the Encoder Layers","metadata":{}},{"cell_type":"markdown","source":"| #  | Module / Concept               | Key Idea / Iconography                                                   | Chosen Value & Reasoning |\n|----|--------------------------------|-------------------------------------------------------------------------|-------------------------|\n| 1Ô∏è‚É£ | Adapter                        | üîß Bottleneck FFN layer; down ‚Üí ReLU ‚Üí up; residual connection; lightweight extra brain; preserves pretrained knowledge | `bottleneck = 64` ‚Üí reduces dimensionality for efficiency, preserves key FFN features, adds residual for stability |\n| 2Ô∏è‚É£ | LoRA: Preserve Knowledge       | üß† Base model frozen; ü™Ñ LoRA trains small matrices; üõ°Ô∏è avoids forgetting | `r = 8` ‚Üí low-rank; balances trainable parameters and learning capacity |\n| 3Ô∏è‚É£ | LoRA: Efficient Adaptation     | ‚ö° Small dataset; üìâ less compute; üìù captures new vocab & grammar       | Uses low-rank adapters ‚Üí efficient adaptation without full fine-tuning |\n| 4Ô∏è‚É£ | LoRA: Task & Language Specific | üéØ Target key layers (Q/K/V); üí° efficient adaptation                   | Focus on attention matrices ‚Üí most impact for cross-lingual transfer |\n| 5Ô∏è‚É£ | LoRA: Swap / Combine Languages | üîÑ Multiple adapters; üåè load per language; üèóÔ∏è base model unchanged     | Separate adapters per language ‚Üí modular and flexible multilingual support |\n| üí° | LoRA Analogy                   | üìò Base = polyglot student; LoRA = Bangla phrasebook, lightweight & safe| Analogy clarifies purpose and efficiency |\n| 6Ô∏è‚É£ | LoRA Integration               | üèóÔ∏è LoRA added to q/k/v in all encoder blocks; Adapter added from block 2 onwards; efficiently adapts model without full fine-tuning | Combines Adapter + LoRA ‚Üí minimal trainable parameters, maximal adaptation |\n","metadata":{}},{"cell_type":"markdown","source":"### Lightweight Extran Brain in Encoder","metadata":{}},{"cell_type":"code","source":"# üîß Purpose: Adapter module for parameter-efficient fine-tuning\nclass Adapter(nn.Module):\n    def __init__(self, hidden_size, bottleneck=None):\n        \"\"\"\n        Adapter layer:\n        - Projects down to a smaller bottleneck dimension\n        - Applies ReLU activation\n        - Projects back to hidden size\n        - Adds a residual connection\n        \"\"\"\n        super().__init__()\n        if bottleneck is None:\n            bottleneck = min(hidden_size // 8, 64)\n        \n        self.down = nn.Linear(hidden_size, bottleneck) # Dim reduction\n        self.relu = nn.ReLU()                          # Non-linearity            \n        self.up = nn.Linear(bottleneck, hidden_size)   # Dim restoration\n\n    def forward(self, x):\n        # Residual connection: output = Adapter(x) + x\n        return x + self.up(self.relu(self.down(x)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T17:01:17.758750Z","iopub.execute_input":"2025-08-25T17:01:17.759467Z","iopub.status.idle":"2025-08-25T17:01:17.764138Z","shell.execute_reply.started":"2025-08-25T17:01:17.759438Z","shell.execute_reply":"2025-08-25T17:01:17.763468Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"#### Add LoRALinear Layer\n","metadata":{}},{"cell_type":"code","source":"# üîó Purpose: LoRALinear wraps a standard Linear layer with Low-Rank Adapters (LoRA)\nclass LoRALinear(nn.Module):\n    def __init__(self, linear, r=8):\n        \"\"\"\n        LoRA-enhanced Linear layer.\n        - Keeps the original linear transformation frozen.\n        - Adds trainable low-rank matrices A (down projection) and B (up projection).\n        \n        Args:\n            linear (nn.Linear): The original linear layer to wrap.\n            r (int): Rank of the low-rank adapters (small number, e.g., 4).\n        \"\"\"\n        super().__init__()\n        self.linear = linear   # Original pretrained layer (can be frozen)\n        self.r = r\n\n        in_features = linear.in_features\n        out_features = linear.out_features\n\n        if r > 0:\n            # üü¢ LoRA low-rank adapters\n            self.A = nn.Linear(in_features, r, bias=False)   # Down-projection\n            self.B = nn.Linear(r, out_features, bias=False)  # Up-projection\n        else:\n            self.A = None\n            self.B = None\n\n    def forward(self, x):\n        if self.r > 0:\n            # Output = frozen original + LoRA update\n            return self.linear(x) + self.B(self.A(x))\n        else:\n            return self.linear(x) \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T17:01:23.346332Z","iopub.execute_input":"2025-08-25T17:01:23.346610Z","iopub.status.idle":"2025-08-25T17:01:23.352275Z","shell.execute_reply.started":"2025-08-25T17:01:23.346591Z","shell.execute_reply":"2025-08-25T17:01:23.351565Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"### Add LoRA and Adapter","metadata":{}},{"cell_type":"code","source":"# Add LoRA and Adapters to T5 Encoder Blocks\nfor i, block in enumerate(model.encoder.block):\n    sa = block.layer[0].SelfAttention\n    \n    # --- Add LoRA to q, k, v ---\n    # --- Wrap existing q, k, v with LoRA ---\n    sa.q = LoRALinear(sa.q, r=8)\n    sa.k = LoRALinear(sa.k, r=8)\n    sa.v = LoRALinear(sa.v, r=8)\n    \n    # --- Adapter only from block 2 onwards ---\n    if i >= 2:\n        ff = block.layer[1].DenseReluDense   # <-- encoder FFN is at layer[1], not layer[2]\n        hidden_size = ff.wo.out_features\n        ff.adapter = Adapter(hidden_size=hidden_size) # match FFN output size\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T17:01:29.155795Z","iopub.execute_input":"2025-08-25T17:01:29.156091Z","iopub.status.idle":"2025-08-25T17:01:29.170101Z","shell.execute_reply.started":"2025-08-25T17:01:29.156070Z","shell.execute_reply":"2025-08-25T17:01:29.169346Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"print(\"======== Model Status after Customized the Encoder Section =========\")\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T17:01:33.687579Z","iopub.execute_input":"2025-08-25T17:01:33.688238Z","iopub.status.idle":"2025-08-25T17:01:33.697600Z","shell.execute_reply.started":"2025-08-25T17:01:33.688203Z","shell.execute_reply":"2025-08-25T17:01:33.696840Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"======== Model Status after Customized the Encoder Section =========\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(37780, 512)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(37780, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): LoRALinear(\n                (linear): Linear(in_features=512, out_features=512, bias=False)\n                (A): Linear(in_features=512, out_features=8, bias=False)\n                (B): Linear(in_features=8, out_features=512, bias=False)\n              )\n              (k): LoRALinear(\n                (linear): Linear(in_features=512, out_features=512, bias=False)\n                (A): Linear(in_features=512, out_features=8, bias=False)\n                (B): Linear(in_features=8, out_features=512, bias=False)\n              )\n              (v): LoRALinear(\n                (linear): Linear(in_features=512, out_features=512, bias=False)\n                (A): Linear(in_features=512, out_features=8, bias=False)\n                (B): Linear(in_features=8, out_features=512, bias=False)\n              )\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.3, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n        )\n      )\n      (1): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): LoRALinear(\n                (linear): Linear(in_features=512, out_features=512, bias=False)\n                (A): Linear(in_features=512, out_features=8, bias=False)\n                (B): Linear(in_features=8, out_features=512, bias=False)\n              )\n              (k): LoRALinear(\n                (linear): Linear(in_features=512, out_features=512, bias=False)\n                (A): Linear(in_features=512, out_features=8, bias=False)\n                (B): Linear(in_features=8, out_features=512, bias=False)\n              )\n              (v): LoRALinear(\n                (linear): Linear(in_features=512, out_features=512, bias=False)\n                (A): Linear(in_features=512, out_features=8, bias=False)\n                (B): Linear(in_features=8, out_features=512, bias=False)\n              )\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.3, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n        )\n      )\n      (2-6): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): LoRALinear(\n                (linear): Linear(in_features=512, out_features=512, bias=False)\n                (A): Linear(in_features=512, out_features=8, bias=False)\n                (B): Linear(in_features=8, out_features=512, bias=False)\n              )\n              (k): LoRALinear(\n                (linear): Linear(in_features=512, out_features=512, bias=False)\n                (A): Linear(in_features=512, out_features=8, bias=False)\n                (B): Linear(in_features=8, out_features=512, bias=False)\n              )\n              (v): LoRALinear(\n                (linear): Linear(in_features=512, out_features=512, bias=False)\n                (A): Linear(in_features=512, out_features=8, bias=False)\n                (B): Linear(in_features=8, out_features=512, bias=False)\n              )\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.3, inplace=False)\n              (act): ReLU()\n              (adapter): Adapter(\n                (down): Linear(in_features=512, out_features=64, bias=True)\n                (relu): ReLU()\n                (up): Linear(in_features=64, out_features=512, bias=True)\n              )\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.3, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(37780, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.3, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n        )\n      )\n      (1-6): 6 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.3, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.3, inplace=False)\n  )\n  (lm_head): Linear(in_features=512, out_features=37780, bias=False)\n)"},"metadata":{}}],"execution_count":26},{"cell_type":"markdown","source":"## üöÄ Add Adaptive Attention in Decoder Sections","metadata":{}},{"cell_type":"markdown","source":"| #  | Module / Concept           | Key Idea / Iconography                                                   | Chosen Value & Reasoning |\n|----|----------------------------|-------------------------------------------------------------------------|-------------------------|\n| 1Ô∏è‚É£ | Adaptive Attention + Gating | üéØ Gate network adaptively combines encoder & decoder states; ‚ö° context scaled by learnable parameter; üîë improves cross-attention focus | `hidden_size = 512` ‚Üí matches T5-small decoder; `scale = ones(hidden_size)` ‚Üí learnable scaling preserves magnitude; gate = linear(hidden_size, hidden_size) for per-dim adaptive weighting |\n| 2Ô∏è‚É£ | Integration into Decoder   | üèóÔ∏è Added after FFN / layer[1] in each decoder block; replaces static cross-attention output with gated adaptive output | Ensures decoder effectively balances source context & own hidden states; improves translation accuracy without modifying base attention |\n","metadata":{}},{"cell_type":"code","source":"# üéØ Purpose: Adaptive Attention with gating mechanism\nclass AdaptiveAttention(nn.Module):\n    def __init__(self, hidden_size):\n        super().__init__()\n        # üîë Gating network to adaptively weight encoder vs decoder states\n        self.gate = nn.Linear(hidden_size, hidden_size)\n        self.scale = nn.Parameter(torch.ones(hidden_size))  # learnable scaling\n\n    def forward(self, decoder_hidden, encoder_outputs):\n        \"\"\"\n        decoder_hidden: [batch, tgt_len, hidden_size]\n        encoder_outputs: [batch, src_len, hidden_size]\n        \"\"\"\n        # 1Ô∏è‚É£ Compute attention scores\n        attn_scores = torch.matmul(decoder_hidden, encoder_outputs.transpose(1, 2))  \n        attn_weights = F.softmax(attn_scores, dim=-1)  # [batch, tgt_len, src_len]\n\n        # 2Ô∏è‚É£ Context vector\n        context = torch.matmul(attn_weights, encoder_outputs)  # [batch, tgt_len, hidden_size]\n\n        # 3Ô∏è‚É£ Adaptive gating\n        gate = torch.sigmoid(self.gate(decoder_hidden))  # [batch, tgt_len, hidden_size]\n        adaptive_output = gate * context * self.scale + (1 - gate) * decoder_hidden\n\n        return adaptive_output\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T17:01:43.233659Z","iopub.execute_input":"2025-08-25T17:01:43.233966Z","iopub.status.idle":"2025-08-25T17:01:43.239958Z","shell.execute_reply.started":"2025-08-25T17:01:43.233942Z","shell.execute_reply":"2025-08-25T17:01:43.239120Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"#Add AdaptiveAttention after running layer[1], it runs adaptive_attention.\nfor i, block in enumerate(model.decoder.block):\n    cross_attn = block.layer[1]  # cross-attention\n    block.adaptive_attention = AdaptiveAttention(hidden_size=512)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T17:01:48.077414Z","iopub.execute_input":"2025-08-25T17:01:48.077706Z","iopub.status.idle":"2025-08-25T17:01:48.097978Z","shell.execute_reply.started":"2025-08-25T17:01:48.077685Z","shell.execute_reply":"2025-08-25T17:01:48.097288Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"### üîë Save and Load Final Custom Model","metadata":{}},{"cell_type":"code","source":"print(\"======== Model Status after Customized the Encoder and Decoder Section =========\")\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T21:17:05.643033Z","iopub.execute_input":"2025-08-25T21:17:05.643793Z","iopub.status.idle":"2025-08-25T21:17:05.651341Z","shell.execute_reply.started":"2025-08-25T21:17:05.643770Z","shell.execute_reply":"2025-08-25T21:17:05.650763Z"}},"outputs":[{"name":"stdout","text":"======== Model Status after Customized the Encoder and Decoder Section =========\n","output_type":"stream"},{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(37780, 512)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(37780, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): LoRALinear(\n                (linear): Linear(in_features=512, out_features=512, bias=False)\n                (A): Linear(in_features=512, out_features=8, bias=False)\n                (B): Linear(in_features=8, out_features=512, bias=False)\n              )\n              (k): LoRALinear(\n                (linear): Linear(in_features=512, out_features=512, bias=False)\n                (A): Linear(in_features=512, out_features=8, bias=False)\n                (B): Linear(in_features=8, out_features=512, bias=False)\n              )\n              (v): LoRALinear(\n                (linear): Linear(in_features=512, out_features=512, bias=False)\n                (A): Linear(in_features=512, out_features=8, bias=False)\n                (B): Linear(in_features=8, out_features=512, bias=False)\n              )\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.3, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n        )\n      )\n      (1): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): LoRALinear(\n                (linear): Linear(in_features=512, out_features=512, bias=False)\n                (A): Linear(in_features=512, out_features=8, bias=False)\n                (B): Linear(in_features=8, out_features=512, bias=False)\n              )\n              (k): LoRALinear(\n                (linear): Linear(in_features=512, out_features=512, bias=False)\n                (A): Linear(in_features=512, out_features=8, bias=False)\n                (B): Linear(in_features=8, out_features=512, bias=False)\n              )\n              (v): LoRALinear(\n                (linear): Linear(in_features=512, out_features=512, bias=False)\n                (A): Linear(in_features=512, out_features=8, bias=False)\n                (B): Linear(in_features=8, out_features=512, bias=False)\n              )\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.3, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n        )\n      )\n      (2-6): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): LoRALinear(\n                (linear): Linear(in_features=512, out_features=512, bias=False)\n                (A): Linear(in_features=512, out_features=8, bias=False)\n                (B): Linear(in_features=8, out_features=512, bias=False)\n              )\n              (k): LoRALinear(\n                (linear): Linear(in_features=512, out_features=512, bias=False)\n                (A): Linear(in_features=512, out_features=8, bias=False)\n                (B): Linear(in_features=8, out_features=512, bias=False)\n              )\n              (v): LoRALinear(\n                (linear): Linear(in_features=512, out_features=512, bias=False)\n                (A): Linear(in_features=512, out_features=8, bias=False)\n                (B): Linear(in_features=8, out_features=512, bias=False)\n              )\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.3, inplace=False)\n              (act): ReLU()\n              (adapter): Adapter(\n                (down): Linear(in_features=512, out_features=64, bias=True)\n                (relu): ReLU()\n                (up): Linear(in_features=64, out_features=512, bias=True)\n              )\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.3, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(37780, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.3, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n        )\n        (adaptive_attention): AdaptiveAttention(\n          (gate): Linear(in_features=512, out_features=512, bias=True)\n        )\n      )\n      (1-6): 6 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.3, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n        )\n        (adaptive_attention): AdaptiveAttention(\n          (gate): Linear(in_features=512, out_features=512, bias=True)\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.3, inplace=False)\n  )\n  (lm_head): Linear(in_features=512, out_features=37780, bias=False)\n)"},"metadata":{}}],"execution_count":80},{"cell_type":"markdown","source":"\n### T5 Model config (after edits)\n| Setting                      | Value                              | Purpose (plain English)                                  |\n|-----------------------------|------------------------------------|-----------------------------------------------------------|\n| Base model                  | t5-small                           | Start from strong pretrained weights                      |\n| Encoder layers              | 7 (6 + 1 extra)                    | Extra capacity to learn Bangla nuances                    |\n| Decoder layers              | 7 (6 + 1 extra)                    | Extra capacity for fluent, faithful English generation    |\n| dropout_rate                | 0.3 (‚Üë from 0.1)                   | Reduce overfitting; make representations more robust      |\n| attention_dropout_rate      | 0.3 (‚Üë from 0.1)                   | Regularize attention; prevent head over-reliance          |\n| layerdrop                   | 0.2                                | Randomly drop layers during training ‚Üí better generalization |\n| Relative attention bias     | First block only (unchanged)       | Stable positional inductive bias                          |\n| Extra blocks‚Äô rel. bias     | `has_relative_attention_bias=False`| Keep bias placement consistent with T5 design             |\n\n### Training plan (what to freeze vs train)\n| Part                       | Trainable? | Purpose (why this choice)                                       |\n|---------------------------|------------|------------------------------------------------------------------|\n| `model.shared` embedding  | ‚ùå Frozen   | Keep core token meanings stable across Bangla/English            |\n| Encoder layers 0‚Äì2        | ‚ùå Frozen   | Preserve general syntax/semantics from pretraining               |\n| Encoder layers 3‚Äì6        | ‚úÖ Train    | Adapt higher layers to Bangla grammar & context                  |\n| Decoder layers 0‚Äì6        | ‚úÖ Train    | Produce fluent, accurate English aligned to Bangla input         |\n| LM head (output layer)    | ‚úÖ Train    | Map decoder states ‚Üí target vocabulary effectively                |\n\n> Notes: layer indices are 0-based. With your added blocks, there are **7 encoder** and **7 decoder** layers total.\n\n### Summary Table\n\n| Part                                 | Trainable?      | Purpose / Notes                                         |\n| ------------------------------------ | --------------- | ------------------------------------------------------ |\n| Custom vocab                          | ‚úÖ Trainable     | Existing tokens: 32,100 + New tokens: 5,680 ‚Üí expand tokenizer with new tokens |\n| `model.shared` (embedding)           | ‚ùå Frozen        | Input representation                                     |\n| Encoder layers 0‚Äì2                    | ‚ùå Frozen        | Preserve pretrained knowledge                            |\n| Encoder layers 3‚ÄìN                    | ‚úÖ Trainable     | Adapt to Bangla understanding                            |\n| Decoder layers 0‚ÄìN                    | ‚úÖ Trainable     | Generate English output                                  |\n| LM head                               | ‚úÖ Trainable     | Map hidden ‚Üí vocabulary                                  |\n| `Adapter` modules in encoder/decoder | ‚úÖ Trainable     | Parameter-efficient fine-tuning                           |\n| `LoRALinear` (attention layers)       | ‚úÖ Trainable     | Inject low-rank updates without full fine-tuning         |\n| `AdaptiveAttention` in decoder        | ‚úÖ Trainable     | Dynamically balance encoder vs decoder states            |\n\n\n","metadata":{}},{"cell_type":"markdown","source":"# üõ†Ô∏è Feature and Target","metadata":{}},{"cell_type":"code","source":"# After loading and optionally renaming columns in val_dataset\n\n# Convert train dataset columns to lists\ntrain_texts = training_dataset[\"Text\"].tolist()      # Bangla sentences\ntrain_targets = training_dataset[\"Target\"].tolist()  # English translations\n\n# Convert val dataset columns to lists\nval_texts = valid_dataset[\"Text\"].tolist()      # Bangla sentences\nval_targets = valid_dataset[\"Target\"].tolist()  # English translations\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T17:02:04.991719Z","iopub.execute_input":"2025-08-25T17:02:04.992612Z","iopub.status.idle":"2025-08-25T17:02:05.004614Z","shell.execute_reply.started":"2025-08-25T17:02:04.992573Z","shell.execute_reply":"2025-08-25T17:02:05.003692Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"print(f\"üìå Training Inputs Size: {len(train_texts)} and Training Target Size: {len(train_targets)}\")\nprint(f\"üìå Validation Inputs Size: {len(val_texts)} and Training Target Size: {len(val_targets)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T17:02:06.988680Z","iopub.execute_input":"2025-08-25T17:02:06.989421Z","iopub.status.idle":"2025-08-25T17:02:06.994583Z","shell.execute_reply.started":"2025-08-25T17:02:06.989384Z","shell.execute_reply":"2025-08-25T17:02:06.993744Z"}},"outputs":[{"name":"stdout","text":"üìå Training Inputs Size: 4008 and Training Target Size: 4008\nüìå Validation Inputs Size: 945 and Training Target Size: 945\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# ================================\n# Remove empty or NaN entries\n# ================================\ntrain_texts = [str(t) for t in train_texts if str(t).strip() != \"\"]\ntrain_targets = [str(t) for t in train_targets if str(t).strip() != \"\"]\nval_texts = [str(t) for t in val_texts if str(t).strip() != \"\"]\nval_targets = [str(t) for t in val_targets if str(t).strip() != \"\"]\n\n# Optional: check sizes after cleaning\nprint(f\"üìå Training Inputs Size: {len(train_texts)} and Training Target Size: {len(train_targets)}\")\nprint(f\"üìå Validation Inputs Size: {len(val_texts)} and Validation Target Size: {len(val_targets)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T17:02:10.896220Z","iopub.execute_input":"2025-08-25T17:02:10.896510Z","iopub.status.idle":"2025-08-25T17:02:10.904402Z","shell.execute_reply.started":"2025-08-25T17:02:10.896488Z","shell.execute_reply":"2025-08-25T17:02:10.903419Z"}},"outputs":[{"name":"stdout","text":"üìå Training Inputs Size: 4008 and Training Target Size: 4008\nüìå Validation Inputs Size: 945 and Validation Target Size: 945\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"### üó∫Ô∏è Max Length of Text and Target ","metadata":{}},{"cell_type":"code","source":"train_source_lens = [len(tokenizer.encode(text)) for text in train_texts]\ntrain_target_lens = [len(tokenizer.encode(text)) for text in train_targets]\n\nprint(\"Train Source lengths - max:\", max(train_source_lens), \"mean:\", sum(train_source_lens)/len(train_source_lens))\nprint(\"Train Target lengths - max:\", max(train_target_lens), \"mean:\", sum(train_target_lens)/len(train_target_lens))\n\n\nval_source_lens = [len(tokenizer.encode(text)) for text in val_texts]\nval_target_lens = [len(tokenizer.encode(text)) for text in val_targets]\n\nprint(\"Val Source lengths - max:\", max(val_source_lens), \"mean:\", sum(val_source_lens)/len(val_source_lens))\nprint(\"Val Target lengths - max:\", max(val_target_lens), \"mean:\", sum(val_target_lens)/len(val_target_lens))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T17:02:14.454696Z","iopub.execute_input":"2025-08-25T17:02:14.455000Z","iopub.status.idle":"2025-08-25T17:02:17.437193Z","shell.execute_reply.started":"2025-08-25T17:02:14.454978Z","shell.execute_reply":"2025-08-25T17:02:17.436437Z"}},"outputs":[{"name":"stdout","text":"Train Source lengths - max: 178 mean: 71.05963073852296\nTrain Target lengths - max: 229 mean: 77.11801397205589\nVal Source lengths - max: 159 mean: 78.07619047619048\nVal Target lengths - max: 157 mean: 86.34391534391534\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"### üîπ Tokenization & Encoding for Seq2Seq Training\n\n**Caption:** Prepares source and target sequences for training by tokenizing, padding, truncating, and masking padding tokens in labels.\n\n**Short Summary:**  \nThis function converts raw source and target texts into token IDs suitable for the model. It also prepares labels with `-100` for padding tokens so that the loss is not computed on them.\n","metadata":{}},{"cell_type":"code","source":"\n# === Constants ===\nSRC_MAX_LEN = 200\nTGT_MAX_LEN = 250\n#BATCH_SIZE = 8  # Adjust as needed\n\n# === Encoding Function ===\ndef prepare_encodings(source_texts, target_texts, tokenizer, src_max_len, tgt_max_len):\n    \"\"\"\n    Tokenizes source and target texts, prepares labels with -100 padding mask.\n    Returns: input_encodings, labels\n    \"\"\"\n    # Tokenize source (input) texts\n    input_encodings = tokenizer(\n        source_texts,\n        padding=\"max_length\",\n        truncation=True,\n        max_length=src_max_len,\n        return_tensors=\"pt\"\n    )\n    input_encodings[\"input_ids\"] = input_encodings[\"input_ids\"].long()\n    input_encodings[\"attention_mask\"] = input_encodings[\"attention_mask\"].long()\n\n    # Tokenize target (label) texts\n    target_encodings = tokenizer(\n        target_texts,\n        padding=\"max_length\",\n        truncation=True,\n        max_length=tgt_max_len,\n        return_tensors=\"pt\"\n    )\n    target_encodings[\"input_ids\"] = target_encodings[\"input_ids\"].long()\n    target_encodings[\"attention_mask\"] = target_encodings[\"attention_mask\"].long()\n\n    # Prepare labels (mask pad tokens)\n    labels = target_encodings[\"input_ids\"].clone()\n    labels[labels == tokenizer.pad_token_id] = -100\n\n    return input_encodings, labels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T17:02:35.158149Z","iopub.execute_input":"2025-08-25T17:02:35.158479Z","iopub.status.idle":"2025-08-25T17:02:35.164236Z","shell.execute_reply.started":"2025-08-25T17:02:35.158456Z","shell.execute_reply":"2025-08-25T17:02:35.163552Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"# === Prepare tokenized inputs and labels for training data ===\ntrain_input_encodings, train_labels = prepare_encodings(\n    train_texts, train_targets, tokenizer, SRC_MAX_LEN, TGT_MAX_LEN\n)\n\n# === Prepare tokenized inputs and labels for validation data ===\nval_input_encodings, val_labels = prepare_encodings(\n    val_texts, val_targets, tokenizer, SRC_MAX_LEN, TGT_MAX_LEN\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T17:02:40.949351Z","iopub.execute_input":"2025-08-25T17:02:40.949655Z","iopub.status.idle":"2025-08-25T17:02:44.678902Z","shell.execute_reply.started":"2025-08-25T17:02:40.949622Z","shell.execute_reply":"2025-08-25T17:02:44.678018Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"# === Print and Decode Train Example ===\nprint(\"\\n=== [Train] Input Encodings (Bangla) ===\")\nprint(\"input_ids:\\n\", train_input_encodings[\"input_ids\"])\nprint(\"attention_mask:\\n\", train_input_encodings[\"attention_mask\"])\n\nprint(\"\\n=== [Train] Target Encodings (English) ===\")\ntrain_target_ids = train_labels.clone()\ntrain_target_ids[train_target_ids == -100] = tokenizer.pad_token_id  # For decoding\nprint(\"input_ids:\\n\", train_target_ids)\n\n# Decode first train example\nprint(\"\\n First train input (decoded):\", tokenizer.decode(train_input_encodings[\"input_ids\"][700], skip_special_tokens=True))\nprint(\"\\n First train target (decoded):\", tokenizer.decode(train_target_ids[700], skip_special_tokens=True))\n\n# === Print and Decode Val Example ===\nprint(\"\\n=== [Val] Input Encodings (Bangla) ===\")\nprint(\"input_ids:\\n\", val_input_encodings[\"input_ids\"])\nprint(\"attention_mask:\\n\", val_input_encodings[\"attention_mask\"])\n\nprint(\"\\n=== [Val] Target Encodings (English) ===\")\nval_target_ids = val_labels.clone()\nval_target_ids[val_target_ids == -100] = tokenizer.pad_token_id  # For decoding\nprint(\"input_ids:\\n\", val_target_ids)\n\n# Decode first val example\nprint(\"\\n First val input (decoded):\", tokenizer.decode(val_input_encodings[\"input_ids\"][0], skip_special_tokens=True))\nprint(\"\\n First val target (decoded):\", tokenizer.decode(val_target_ids[0], skip_special_tokens=True))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T17:02:44.680042Z","iopub.execute_input":"2025-08-25T17:02:44.680276Z","iopub.status.idle":"2025-08-25T17:02:44.776358Z","shell.execute_reply.started":"2025-08-25T17:02:44.680258Z","shell.execute_reply":"2025-08-25T17:02:44.775644Z"}},"outputs":[{"name":"stdout","text":"\n=== [Train] Input Encodings (Bangla) ===\ninput_ids:\n tensor([[37686,     3,    23,  ...,     0,     0,     0],\n        [37686,     3,    23,  ...,     0,     0,     0],\n        [37686,     3,    23,  ...,     0,     0,     0],\n        ...,\n        [  205, 35260,     3,  ...,     0,     0,     0],\n        [  411, 34902,     3,  ...,     0,     0,     0],\n        [32757,     3,    29,  ...,     0,     0,     0]])\nattention_mask:\n tensor([[1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        ...,\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0]])\n\n=== [Train] Target Encodings (English) ===\ninput_ids:\n tensor([[  571,    33, 34770,  ...,     0,     0,     0],\n        [  571,     3,   107,  ...,     0,     0,     0],\n        [ 1521, 34770,     3,  ...,     0,     0,     0],\n        ...,\n        [  180, 32442, 36675,  ...,     0,     0,     0],\n        [  205, 33328,  6397,  ...,     0,     0,     0],\n        [32757,     3,    29,  ...,     0,     0,     0]])\n\n First train input (decoded): ‡¶Ü‡¶™ ‡¶®‡¶ø ‡¶ï‡¶ø ‡¶Ü‡¶ú ‡¶ï‡ßá m et ro ‡¶¨‡¶æ s ub wa y ‡¶¨‡ßç‡¶Ø ‡¶¨ ‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞ ‡¶¨‡ßá‡¶®? ‡¶Ü‡¶Æ‡¶ø ‡¶≠‡¶æ‡¶¨ ‡¶õ‡¶ø‡¶≤‡¶æ‡¶Æ ti cket properly bo oke d ‡¶Ü ‡¶õ‡ßá ‡¶ï‡¶ø ‡¶®‡¶æ ‡•§ If c ro wd ‡¶¨‡ßá‡¶∂ ‡¶ø ‡¶π ‡¶Ø‡¶º, ‡¶Ü ‡¶Æ‡¶∞ ‡¶æ ne xt trai n ‡¶®‡¶ø ‡¶§‡ßá ‡¶™‡¶æ ‡¶∞‡¶ø ‡•§\n\n First train target (decoded): Wi ll yo u u se the m et ro or s ub wa y t oda y? I wa s thin king wh et her yo ur ti cket is properly bo oke d. If it‚Äôs c ro wd ed, we can ta ke the ne xt trai n.\n\n=== [Val] Input Encodings (Bangla) ===\ninput_ids:\n tensor([[37686,  1584,     3,  ...,     0,     0,     0],\n        [37686,     3,    23,  ...,     0,     0,     0],\n        [   71,   354,  1050,  ...,     0,     0,     0],\n        ...,\n        [37776, 35680, 34126,  ...,     0,     0,     0],\n        [33763, 32567, 34175,  ...,     0,     0,     0],\n        [32863, 32390, 32363,  ...,     0,     0,     0]])\nattention_mask:\n tensor([[1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        ...,\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0]])\n\n=== [Val] Target Encodings (English) ===\ninput_ids:\n tensor([[  301, 33578,    12,  ...,     0,     0,     0],\n        [  363,  9564, 37737,  ...,     0,     0,     0],\n        [  332, 36794, 33851,  ...,     0,     0,     0],\n        ...,\n        [   71, 35675,     3,  ...,     0,     0,     0],\n        [36925, 34295, 32869,  ...,     0,     0,     0],\n        [   27, 36722,     3,  ...,     0,     0,     0]])\n\n First val input (decoded): Apn ar k oth a sh u ne ama r khu b shan ti l ag e. K ichu di n d hore a mi ek tu str ess e chhi lam. Apn ar sh om ort hon ama ke o nek sha hosh dey. A mi c hai ama der bo n dhu tto a ro d eep ho k. Apn ar m oto ma nu sh ama r ji bo n e o nek imp ort a nt.\n\n First val target (decoded): L istening to yo u gi ves me p eace. I wa s a bit str essed th ese p ast da ys. Your sup por t gi ves me a lo t of cou ra ge. I wa nt our f ri ends hi p to gr ow d eep er. A pe rs on l ik e yo u is very imp ort a nt in my life.\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"\n# Decode first train example\nprint(\"First train input (decoded):\", tokenizer.decode(train_input_encodings[\"input_ids\"][702], skip_special_tokens=True))\nprint(\"First train target (decoded):\", tokenizer.decode(train_target_ids[701], skip_special_tokens=True, clean_up_tokenization_spaces=True))\n\nprint(\"=========================================================================================================\")\n# Decode first val example\nprint(\"First val input (decoded):\", tokenizer.decode(val_input_encodings[\"input_ids\"][0], skip_special_tokens=True))\nprint(\"First val target (decoded):\", tokenizer.decode(val_target_ids[0], skip_special_tokens=True))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T17:03:05.452142Z","iopub.execute_input":"2025-08-25T17:03:05.452444Z","iopub.status.idle":"2025-08-25T17:03:05.517358Z","shell.execute_reply.started":"2025-08-25T17:03:05.452424Z","shell.execute_reply":"2025-08-25T17:03:05.516607Z"}},"outputs":[{"name":"stdout","text":"First train input (decoded): ‡¶Ü‡¶™ ‡¶®‡¶ø ‡¶ï‡¶ø ‡¶Ü‡¶ú ‡¶ï‡ßá ride - sha re ‡¶ï‡¶∞ ‡¶§‡ßá ‡¶ö‡¶æ ‡¶®? ‡¶Ü‡¶Æ‡¶ø ‡¶≠‡¶æ‡¶¨ ‡¶õ‡¶ø‡¶≤‡¶æ‡¶Æ p assenger properly info rmed ‡¶Ü ‡¶õ‡ßá ‡¶ï‡¶ø ‡¶®‡¶æ ‡•§ S afety preca uti ons ‡¶®‡¶ø ‡¶≤‡ßá b et te r ‡¶π ‡¶¨‡ßá ‡•§\nFirst train target (decoded): Ha ve yo u r ecent ly plan ned a t rave l ro ut e? I wa s thin king wh et her the distance h as b een properly m easure d. F ollo wing the ro ut e will sa ve ti me.\n=========================================================================================================\nFirst val input (decoded): Apn ar k oth a sh u ne ama r khu b shan ti l ag e. K ichu di n d hore a mi ek tu str ess e chhi lam. Apn ar sh om ort hon ama ke o nek sha hosh dey. A mi c hai ama der bo n dhu tto a ro d eep ho k. Apn ar m oto ma nu sh ama r ji bo n e o nek imp ort a nt.\nFirst val target (decoded): L istening to yo u gi ves me p eace. I wa s a bit str essed th ese p ast da ys. Your sup por t gi ves me a lo t of cou ra ge. I wa nt our f ri ends hi p to gr ow d eep er. A pe rs on l ik e yo u is very imp ort a nt in my life.\n","output_type":"stream"}],"execution_count":37},{"cell_type":"markdown","source":"# üîÆ Convert to pytorch Dataset","metadata":{}},{"cell_type":"code","source":"# üìö Purpose: Custom Dataset for seq2seq translation tasks\nclass TranslationDataset(Dataset):\n    def __init__(self, input_encodings, labels):\n        \"\"\"\n        Stores input token IDs, attention masks, and labels for training.\n        \n        Args:\n            input_encodings (dict): Tokenized source sequences from tokenizer\n            labels (torch.Tensor): Target token IDs with padding masked as -100\n        \"\"\"\n        self.input_ids = input_encodings[\"input_ids\"]\n        self.attention_mask = input_encodings[\"attention_mask\"]\n        self.labels = labels\n\n    def __len__(self):\n        # Return number of samples\n        return self.labels.size(0)\n\n    def __getitem__(self, idx):\n        # Return a single sample as a dictionary\n        return {\n            \"input_ids\": self.input_ids[idx],\n            \"attention_mask\": self.attention_mask[idx],\n            \"labels\": self.labels[idx]\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T17:03:15.069492Z","iopub.execute_input":"2025-08-25T17:03:15.069773Z","iopub.status.idle":"2025-08-25T17:03:15.074935Z","shell.execute_reply.started":"2025-08-25T17:03:15.069752Z","shell.execute_reply":"2025-08-25T17:03:15.074091Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"# === Create Datasets ===\ntrain_dataset = TranslationDataset(train_input_encodings, train_labels)\nprint(f\"Convert to Pytorch Train Dataset: {train_dataset}\")\nval_dataset = TranslationDataset(val_input_encodings, val_labels)\nprint(f\"Convert to Pytorch Train Dataset: {val_dataset}\")\n\n# === Create DataLoaders ===\nBATCH_SIZE = 16  # adjust according to GPU memory\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T17:03:19.218670Z","iopub.execute_input":"2025-08-25T17:03:19.218985Z","iopub.status.idle":"2025-08-25T17:03:19.224734Z","shell.execute_reply.started":"2025-08-25T17:03:19.218961Z","shell.execute_reply":"2025-08-25T17:03:19.223912Z"}},"outputs":[{"name":"stdout","text":"Convert to Pytorch Train Dataset: <__main__.TranslationDataset object at 0x7b299887a590>\nConvert to Pytorch Train Dataset: <__main__.TranslationDataset object at 0x7b2999021a50>\n","output_type":"stream"}],"execution_count":39},{"cell_type":"markdown","source":"# üì§ Device Setup","metadata":{}},{"cell_type":"markdown","source":"| Precision     | Usage                       | Device             |\n|---------------|----------------------------|------------------|\n| Float16       | `model.half()`             | GPU only          |\n| Float32       | `model.to(device)`         | GPU or CPU        |\n","metadata":{}},{"cell_type":"code","source":"# === Device Setup ===\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n# float 32\nmodel.to(device)\n\n# float 16 in GPU interface\n#model.half().to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T17:03:25.521961Z","iopub.execute_input":"2025-08-25T17:03:25.522247Z","iopub.status.idle":"2025-08-25T17:03:25.899476Z","shell.execute_reply.started":"2025-08-25T17:03:25.522227Z","shell.execute_reply":"2025-08-25T17:03:25.898739Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(37780, 512)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(37780, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): LoRALinear(\n                (linear): Linear(in_features=512, out_features=512, bias=False)\n                (A): Linear(in_features=512, out_features=8, bias=False)\n                (B): Linear(in_features=8, out_features=512, bias=False)\n              )\n              (k): LoRALinear(\n                (linear): Linear(in_features=512, out_features=512, bias=False)\n                (A): Linear(in_features=512, out_features=8, bias=False)\n                (B): Linear(in_features=8, out_features=512, bias=False)\n              )\n              (v): LoRALinear(\n                (linear): Linear(in_features=512, out_features=512, bias=False)\n                (A): Linear(in_features=512, out_features=8, bias=False)\n                (B): Linear(in_features=8, out_features=512, bias=False)\n              )\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.3, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n        )\n      )\n      (1): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): LoRALinear(\n                (linear): Linear(in_features=512, out_features=512, bias=False)\n                (A): Linear(in_features=512, out_features=8, bias=False)\n                (B): Linear(in_features=8, out_features=512, bias=False)\n              )\n              (k): LoRALinear(\n                (linear): Linear(in_features=512, out_features=512, bias=False)\n                (A): Linear(in_features=512, out_features=8, bias=False)\n                (B): Linear(in_features=8, out_features=512, bias=False)\n              )\n              (v): LoRALinear(\n                (linear): Linear(in_features=512, out_features=512, bias=False)\n                (A): Linear(in_features=512, out_features=8, bias=False)\n                (B): Linear(in_features=8, out_features=512, bias=False)\n              )\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.3, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n        )\n      )\n      (2-6): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): LoRALinear(\n                (linear): Linear(in_features=512, out_features=512, bias=False)\n                (A): Linear(in_features=512, out_features=8, bias=False)\n                (B): Linear(in_features=8, out_features=512, bias=False)\n              )\n              (k): LoRALinear(\n                (linear): Linear(in_features=512, out_features=512, bias=False)\n                (A): Linear(in_features=512, out_features=8, bias=False)\n                (B): Linear(in_features=8, out_features=512, bias=False)\n              )\n              (v): LoRALinear(\n                (linear): Linear(in_features=512, out_features=512, bias=False)\n                (A): Linear(in_features=512, out_features=8, bias=False)\n                (B): Linear(in_features=8, out_features=512, bias=False)\n              )\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.3, inplace=False)\n              (act): ReLU()\n              (adapter): Adapter(\n                (down): Linear(in_features=512, out_features=64, bias=True)\n                (relu): ReLU()\n                (up): Linear(in_features=64, out_features=512, bias=True)\n              )\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.3, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(37780, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.3, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n        )\n        (adaptive_attention): AdaptiveAttention(\n          (gate): Linear(in_features=512, out_features=512, bias=True)\n        )\n      )\n      (1-6): 6 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.3, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.3, inplace=False)\n          )\n        )\n        (adaptive_attention): AdaptiveAttention(\n          (gate): Linear(in_features=512, out_features=512, bias=True)\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.3, inplace=False)\n  )\n  (lm_head): Linear(in_features=512, out_features=37780, bias=False)\n)"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"print(f\"Details of Output layer of model: \\n{model.lm_head}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T17:03:31.333820Z","iopub.execute_input":"2025-08-25T17:03:31.334151Z","iopub.status.idle":"2025-08-25T17:03:31.338727Z","shell.execute_reply.started":"2025-08-25T17:03:31.334127Z","shell.execute_reply":"2025-08-25T17:03:31.337863Z"}},"outputs":[{"name":"stdout","text":"Details of Output layer of model: \nLinear(in_features=512, out_features=37780, bias=False)\n","output_type":"stream"}],"execution_count":41},{"cell_type":"markdown","source":"# üèÜ Model Training and Evaluation","metadata":{}},{"cell_type":"markdown","source":"| #  | Name / Type                     | Short Code Summary / Purpose                                                                 |\n|----|---------------------------------|---------------------------------------------------------------------------------------------|\n| 1Ô∏è‚É£ | `create_optimizer_and_scheduler` | Function: Creates Adafactor optimizer with built-in dynamic LR schedule; no external scheduler needed. |\n| 2Ô∏è‚É£ | `Seq2SeqTrainer`                 | Class: Implements custom seq2seq training loop, validation, early stopping, and model saving. |\n| 3Ô∏è‚É£ | `__init__`                       | Method: Initializes trainer; sets model, tokenizer, dataloaders, device, optimizer, scaler, epochs, patience, and tracking variables. |\n| 4Ô∏è‚É£ | `run_train_epoch`                | Method: Performs one epoch of training; uses mixed precision (`torch.amp`), gradient clipping, and tracks training loss. |\n| 5Ô∏è‚É£ | `run_val_epoch`                  | Method: Performs one epoch of validation; computes average loss; tracks total validation time. |\n| 6Ô∏è‚É£ | `save_model`                     | Method: Saves model and tokenizer to disk; prints path of saved model. |\n| 7Ô∏è‚É£ | `fit`                            | Method: Main training loop; runs train + validation per epoch, applies early stopping, tracks total time. |\n| 8Ô∏è‚É£ | `plot_losses`                    | Method: Plots training and validation loss curves for visual inspection of convergence. |\n| 9Ô∏è‚É£ | `optimizer = Adafactor(...)`     | Adafactor optimizer: Supports relative step learning rate, warmup, and scaling; used for large-scale seq2seq training. |\n| üîü | `self.scaler = GradScaler(...)`  | Mixed precision: Scales gradients to prevent underflow in float16 training; only enabled on GPU. |\n| 11Ô∏è‚É£ | `torch.nn.utils.clip_grad_norm_` | Clips gradients to max norm (1.0) to stabilize training and prevent exploding gradients. |\n| 12Ô∏è‚É£ | `tqdm(self.train_dataloader)`   | Provides progress bar for each training batch with live loss updates. |\n| 13Ô∏è‚É£ | `total_val_time`                | Tracks total cumulative validation time across all epochs; used for monitoring efficiency. |\n","metadata":{}},{"cell_type":"code","source":"# ============================\n# Optimizer & Scheduler\n# ============================\ndef create_optimizer_and_scheduler(model):\n    \"\"\"\n    Creates Adafactor optimizer with built-in dynamic LR schedule.\n    \"\"\"\n    optimizer = Adafactor(\n        model.parameters(),\n        lr=None,              # Let Adafactor handle LR schedule\n        relative_step=True,   # Dynamic LR per step\n        scale_parameter=True, # Better with relative_step=True\n        warmup_init=True      # Warmup + decay\n    )\n\n    # No external scheduler needed, return None\n    scheduler = None\n\n    return optimizer, scheduler\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T18:35:57.743791Z","iopub.execute_input":"2025-08-25T18:35:57.744544Z","iopub.status.idle":"2025-08-25T18:35:57.749577Z","shell.execute_reply.started":"2025-08-25T18:35:57.744509Z","shell.execute_reply":"2025-08-25T18:35:57.748917Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"# ============================\n# Seq2SeqTrainer with Adafactor\n# ============================\nclass Seq2SeqTrainer:\n    def __init__(self, model, tokenizer, train_dataloader, val_dataloader,\n                 epochs=None, patience=None, optimizer=None, device=None):\n        self.model = model\n        self.tokenizer = tokenizer\n        self.train_dataloader = train_dataloader\n        self.val_dataloader = val_dataloader\n        self.device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.epochs = epochs\n        self.patience = patience\n\n        # Use Adafactor with automatic LR schedule if optimizer not provided\n        if optimizer is None:\n            self.optimizer = Adafactor(\n                self.model.parameters(),\n                lr=None,                 # Let Adafactor compute schedule\n                scale_parameter=True,\n                relative_step=True,\n                warmup_init=True,\n                weight_decay=0.0\n            )\n        else:\n            self.optimizer = optimizer\n\n        self.scaler = torch.amp.GradScaler(enabled=(self.device.type == \"cuda\"))\n\n        self.train_losses = []\n        self.val_losses = []\n        self.best_val_loss = float('inf')\n        self.patience_counter = 0\n\n        self.model.to(self.device)\n\n    # -----------------------------\n    # Training one epoch\n    # -----------------------------\n    def run_train_epoch(self, epoch):\n        self.model.train()\n        total_loss = 0.0\n        #Each Epoch start time\n        start_time = time.time()\n        loop = tqdm(self.train_dataloader, desc=f\"Epoch {epoch+1} [Train]\", leave=True)\n\n        for batch in loop:\n            self.optimizer.zero_grad()\n            input_ids = batch[\"input_ids\"].to(self.device)\n            attention_mask = batch[\"attention_mask\"].to(self.device)\n            labels = batch[\"labels\"].to(self.device)\n\n            with torch.amp.autocast(device_type='cuda', enabled=(self.device.type==\"cuda\")):\n                outputs = self.model(input_ids=input_ids,\n                                     attention_mask=attention_mask,\n                                     labels=labels)\n                loss = outputs.loss\n\n            self.scaler.scale(loss).backward()\n            self.scaler.unscale_(self.optimizer)\n            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n            self.scaler.step(self.optimizer)\n            self.scaler.update()\n\n            total_loss += loss.item()\n            loop.set_postfix(loss=loss.item())\n        \n        epoch_time = time.time() - start_time\n        avg_loss = total_loss / len(self.train_dataloader)\n        self.train_losses.append(avg_loss)\n        print(f\"Epoch {epoch+1} Training Loss: {avg_loss:.4f} | Time: {epoch_time:.2f}s\")\n        return avg_loss\n\n    # -----------------------------\n    # Validation one epoch\n    # -----------------------------\n    def run_val_epoch(self, epoch):\n        \n        self.total_val_time = 0.0  # Add this to track total validation time\n\n        self.model.eval()\n        total_loss = 0.0\n        \n        # Start timing\n        start_time = time.time()  \n\n        with torch.no_grad():\n            for batch in self.val_dataloader:\n                input_ids = batch[\"input_ids\"].to(self.device)\n                attention_mask = batch[\"attention_mask\"].to(self.device)\n                labels = batch[\"labels\"].to(self.device)\n\n                outputs = self.model(input_ids=input_ids,\n                                     attention_mask=attention_mask,\n                                     labels=labels)\n                total_loss += outputs.loss.item()\n\n        avg_loss = total_loss / len(self.val_dataloader)\n        self.val_losses.append(avg_loss)\n        #Duration of each epochs\n        epoch_time = time.time() - start_time\n        # Accumulate total validation time\n        self.total_val_time += epoch_time\n        \n        print(f\"Epoch {epoch+1} Validation Loss: {avg_loss:.4f} | Time: {epoch_time:.2f}s\")\n        \n        return avg_loss\n\n    # -----------------------------\n    # Save model\n    # -----------------------------\n    def save_model(self, path=\"t5_custom_model\"):\n        self.model.save_pretrained(path)\n        self.tokenizer.save_pretrained(path)\n        print(f\"Model saved at {path}\")\n\n    # -----------------------------\n    # Training loop with early stopping\n    # -----------------------------\n    def fit(self):\n        print(\"Starting training...\")\n        total_start_time = time.time()\n\n        for epoch in range(self.epochs):\n            self.run_train_epoch(epoch)\n            val_loss = self.run_val_epoch(epoch)\n\n            # Early stopping\n            if val_loss < self.best_val_loss:\n                self.best_val_loss = val_loss\n                self.patience_counter = 0\n                self.save_model()\n            else:\n                self.patience_counter += 1\n                print(f\"No improvement. Patience: {self.patience_counter}/{self.patience}\")\n                if self.patience_counter >= self.patience:\n                    print(\"Early stopping triggered.\")\n                    break\n\n        total_duration = time.time() - total_start_time\n        print(f\"Total training duration: {total_duration:.2f}s\")\n        print(f\"Total validation time: {self.total_val_time:.2f}s\")\n\n\n    # -----------------------------\n    # Plot losses\n    # -----------------------------\n    def plot_losses(self):\n        plt.figure(figsize=(10,5))\n        plt.plot(self.train_losses, label='Train Loss')\n        plt.plot(self.val_losses, label='Val Loss')\n        plt.xlabel('Epoch')\n        plt.ylabel('Loss')\n        plt.title('Training and Validation Loss')\n        plt.legend()\n        plt.grid(True)\n        plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T19:04:11.558797Z","iopub.execute_input":"2025-08-25T19:04:11.559299Z","iopub.status.idle":"2025-08-25T19:04:11.576399Z","shell.execute_reply.started":"2025-08-25T19:04:11.559266Z","shell.execute_reply":"2025-08-25T19:04:11.575841Z"}},"outputs":[],"execution_count":68},{"cell_type":"markdown","source":"| #  | Name / Type                     | Short Code Summary / Purpose                                                                 |\n|----|---------------------------------|---------------------------------------------------------------------------------------------|\n| 1Ô∏è‚É£ | `EPOCHS`                        | Integer: Total number of training epochs; controls how many full passes over the dataset. |\n| 2Ô∏è‚É£ | `PATIENCE`                       | Integer: Number of consecutive epochs without improvement in validation loss before early stopping. |\n| 3Ô∏è‚É£ | `relative_lr`                    | Float / None: Learning rate for Adafactor; `None` allows Adafactor to manage dynamic LR automatically. |\n| 4Ô∏è‚É£ | `optimizer = Adafactor(...)`     | Adafactor optimizer instance: Uses relative step scheduling, warmup, and scaling for stable seq2seq training. |\n| 5Ô∏è‚É£ | `trainer = Seq2SeqTrainer(...)` | Initializes custom trainer with model, tokenizer, dataloaders, optimizer, epochs, patience, and device. |\n| 6Ô∏è‚É£ | `trainer.fit()`                  | Runs full training loop: executes train + validation epochs with early stopping and saves best model. |\n| 7Ô∏è‚É£ | `trainer.plot_losses()`          | Plots training vs validation loss curves for visual evaluation of model convergence. |\n","metadata":{}},{"cell_type":"code","source":"# ============================\n# Training configuration\n# ============================\nEPOCHS = 150        # Set your desired number of epochs\nPATIENCE = 8      # Patience for validation plateau\nrelative_lr = None # None lets Adafactor handle LR automatically\n\n# Create optimizer (Adafactor with relative step scheduling)\noptimizer = Adafactor(\n    model.parameters(),\n    lr=relative_lr,        # None = automatic relative step\n    scale_parameter=True,  # recommended when relative_step=True\n    relative_step=True,    # use Adafactor's internal schedule\n    warmup_init=True,      # enable warmup\n)\n\n# Initialize hybrid trainer\ntrainer = Seq2SeqTrainer(\n    model=model,\n    tokenizer=tokenizer,\n    train_dataloader=train_dataloader,\n    val_dataloader=val_dataloader,\n    epochs=EPOCHS,\n    patience=PATIENCE,\n    optimizer=optimizer,\n    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n)\n\n# Train & plot\ntrainer.fit()\ntrainer.plot_losses()   # plot only train vs val loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T19:06:47.441269Z","iopub.execute_input":"2025-08-25T19:06:47.441927Z","iopub.status.idle":"2025-08-25T20:19:33.133942Z","shell.execute_reply.started":"2025-08-25T19:06:47.441903Z","shell.execute_reply":"2025-08-25T20:19:33.133170Z"}},"outputs":[{"name":"stdout","text":"Starting training...\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:26<00:00,  2.89it/s, loss=5.73]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 Training Loss: 5.7162 | Time: 86.89s\nEpoch 1 Validation Loss: 5.4277 | Time: 15.00s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:26<00:00,  2.91it/s, loss=5.12]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 Training Loss: 5.2253 | Time: 86.31s\nEpoch 2 Validation Loss: 4.9659 | Time: 14.95s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:26<00:00,  2.91it/s, loss=4.55]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 Training Loss: 4.7902 | Time: 86.14s\nEpoch 3 Validation Loss: 4.6893 | Time: 14.95s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.92it/s, loss=4.37]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 Training Loss: 4.4749 | Time: 85.90s\nEpoch 4 Validation Loss: 4.4821 | Time: 15.08s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:26<00:00,  2.91it/s, loss=4.01]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 Training Loss: 4.2251 | Time: 86.14s\nEpoch 5 Validation Loss: 4.2947 | Time: 15.16s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.93it/s, loss=3.92]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 Training Loss: 3.9855 | Time: 85.68s\nEpoch 6 Validation Loss: 4.1165 | Time: 15.11s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.93it/s, loss=3.47]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 Training Loss: 3.7629 | Time: 85.80s\nEpoch 7 Validation Loss: 4.0019 | Time: 14.96s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.92it/s, loss=3.63]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 Training Loss: 3.5986 | Time: 85.96s\nEpoch 8 Validation Loss: 3.9087 | Time: 14.96s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:26<00:00,  2.92it/s, loss=3.47]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 Training Loss: 3.4563 | Time: 86.03s\nEpoch 9 Validation Loss: 3.8327 | Time: 14.97s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:26<00:00,  2.92it/s, loss=3.19]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10 Training Loss: 3.3197 | Time: 86.07s\nEpoch 10 Validation Loss: 3.7459 | Time: 15.00s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.92it/s, loss=3.09]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11 Training Loss: 3.1741 | Time: 85.96s\nEpoch 11 Validation Loss: 3.6039 | Time: 15.07s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.93it/s, loss=2.62]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12 Training Loss: 3.0272 | Time: 85.58s\nEpoch 12 Validation Loss: 3.5228 | Time: 15.15s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.92it/s, loss=2.5] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 13 Training Loss: 2.8769 | Time: 85.85s\nEpoch 13 Validation Loss: 3.4028 | Time: 15.14s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:26<00:00,  2.91it/s, loss=2.62]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14 Training Loss: 2.7272 | Time: 86.15s\nEpoch 14 Validation Loss: 3.2682 | Time: 15.01s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:26<00:00,  2.92it/s, loss=2.68]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15 Training Loss: 2.5792 | Time: 86.04s\nEpoch 15 Validation Loss: 3.1511 | Time: 15.09s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:26<00:00,  2.91it/s, loss=2.38]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16 Training Loss: 2.4420 | Time: 86.12s\nEpoch 16 Validation Loss: 3.0959 | Time: 15.02s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:26<00:00,  2.92it/s, loss=2.24]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17 Training Loss: 2.3077 | Time: 86.07s\nEpoch 17 Validation Loss: 2.9437 | Time: 14.90s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.93it/s, loss=2.17]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18 Training Loss: 2.1835 | Time: 85.72s\nEpoch 18 Validation Loss: 2.8856 | Time: 15.09s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.93it/s, loss=2.34]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19 Training Loss: 2.0611 | Time: 85.76s\nEpoch 19 Validation Loss: 2.8236 | Time: 15.09s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.93it/s, loss=1.65]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20 Training Loss: 1.9514 | Time: 85.66s\nEpoch 20 Validation Loss: 2.7277 | Time: 14.98s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.93it/s, loss=2.02]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21 Training Loss: 1.8490 | Time: 85.74s\nEpoch 21 Validation Loss: 2.6942 | Time: 14.82s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.94it/s, loss=1.69]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22 Training Loss: 1.7565 | Time: 85.36s\nEpoch 22 Validation Loss: 2.6045 | Time: 14.89s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.93it/s, loss=1.49]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23 Training Loss: 1.6709 | Time: 85.74s\nEpoch 23 Validation Loss: 2.5769 | Time: 15.01s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.94it/s, loss=1.68]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24 Training Loss: 1.5928 | Time: 85.42s\nEpoch 24 Validation Loss: 2.5344 | Time: 14.98s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.92it/s, loss=1.51] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 25 Training Loss: 1.5208 | Time: 85.91s\nEpoch 25 Validation Loss: 2.5552 | Time: 15.08s\nNo improvement. Patience: 1/8\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:26<00:00,  2.92it/s, loss=1.93] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 26 Training Loss: 1.4518 | Time: 86.03s\nEpoch 26 Validation Loss: 2.4926 | Time: 14.87s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.93it/s, loss=1.6]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch 27 Training Loss: 1.3923 | Time: 85.53s\nEpoch 27 Validation Loss: 2.4506 | Time: 14.80s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.93it/s, loss=1.39]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 28 Training Loss: 1.3333 | Time: 85.65s\nEpoch 28 Validation Loss: 2.4475 | Time: 14.90s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.93it/s, loss=1.39] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 29 Training Loss: 1.2776 | Time: 85.74s\nEpoch 29 Validation Loss: 2.4362 | Time: 14.87s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.93it/s, loss=1.67] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 30 Training Loss: 1.2295 | Time: 85.68s\nEpoch 30 Validation Loss: 2.4372 | Time: 15.03s\nNo improvement. Patience: 1/8\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.93it/s, loss=1.41] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 31 Training Loss: 1.1837 | Time: 85.69s\nEpoch 31 Validation Loss: 2.4180 | Time: 14.92s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 32 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.94it/s, loss=0.977]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 32 Training Loss: 1.1400 | Time: 85.33s\nEpoch 32 Validation Loss: 2.3982 | Time: 14.91s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 33 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.95it/s, loss=1.14] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 33 Training Loss: 1.0997 | Time: 85.22s\nEpoch 33 Validation Loss: 2.4138 | Time: 14.92s\nNo improvement. Patience: 1/8\n","output_type":"stream"},{"name":"stderr","text":"Epoch 34 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.93it/s, loss=1.2]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch 34 Training Loss: 1.0608 | Time: 85.79s\nEpoch 34 Validation Loss: 2.3858 | Time: 14.85s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 35 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.93it/s, loss=1.07] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 35 Training Loss: 1.0270 | Time: 85.63s\nEpoch 35 Validation Loss: 2.3800 | Time: 15.01s\nModel saved at t5_custom_model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 36 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.93it/s, loss=1.14] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 36 Training Loss: 0.9935 | Time: 85.77s\nEpoch 36 Validation Loss: 2.4356 | Time: 14.98s\nNo improvement. Patience: 1/8\n","output_type":"stream"},{"name":"stderr","text":"Epoch 37 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.93it/s, loss=0.939]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 37 Training Loss: 0.9632 | Time: 85.61s\nEpoch 37 Validation Loss: 2.4177 | Time: 15.06s\nNo improvement. Patience: 2/8\n","output_type":"stream"},{"name":"stderr","text":"Epoch 38 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.92it/s, loss=0.864]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 38 Training Loss: 0.9320 | Time: 85.90s\nEpoch 38 Validation Loss: 2.4067 | Time: 15.01s\nNo improvement. Patience: 3/8\n","output_type":"stream"},{"name":"stderr","text":"Epoch 39 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.94it/s, loss=0.596]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 39 Training Loss: 0.9062 | Time: 85.34s\nEpoch 39 Validation Loss: 2.3971 | Time: 15.06s\nNo improvement. Patience: 4/8\n","output_type":"stream"},{"name":"stderr","text":"Epoch 40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.94it/s, loss=0.996]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 40 Training Loss: 0.8820 | Time: 85.26s\nEpoch 40 Validation Loss: 2.3936 | Time: 14.88s\nNo improvement. Patience: 5/8\n","output_type":"stream"},{"name":"stderr","text":"Epoch 41 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.94it/s, loss=1.23] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 41 Training Loss: 0.8536 | Time: 85.38s\nEpoch 41 Validation Loss: 2.3875 | Time: 14.98s\nNo improvement. Patience: 6/8\n","output_type":"stream"},{"name":"stderr","text":"Epoch 42 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.95it/s, loss=0.697]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 42 Training Loss: 0.8178 | Time: 85.10s\nEpoch 42 Validation Loss: 2.4609 | Time: 14.91s\nNo improvement. Patience: 7/8\n","output_type":"stream"},{"name":"stderr","text":"Epoch 43 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [01:25<00:00,  2.94it/s, loss=0.951]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 43 Training Loss: 0.7875 | Time: 85.47s\nEpoch 43 Validation Loss: 2.4182 | Time: 14.94s\nNo improvement. Patience: 8/8\nEarly stopping triggered.\nTotal training duration: 4365.53s\nTotal validation time: 14.94s\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x500 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":70},{"cell_type":"markdown","source":"# üéØ Summary\n\nThe original T5 model had no Bangla knowledge. We **added 5,680 new tokens** for mixed Bangla-English input, enabling the model to **start learning Bangla** while retaining English.\n\nTraining and validation datasets were prepared separately. **Training loss dropped steadily**, showing effective learning, while **validation loss plateaued** (~2.39‚Äì2.46), triggering **early stopping** after 8 patience epochs.\n\n**Key Observations:**  \n- üîπ **Training Loss:** dropped from **0.8820 ‚Üí 0.7875** over the last few epochs.  \n- üîπ **Validation Loss:** remained **2.39‚Äì2.46**, indicating stable but limited generalization.  \n- üîπ **Early Stopping:** triggered after **8 epochs** without improvement, preventing overfitting.\n\n**Justification:**  \n- ‚úÖ Training loss drop confirms the model is **learning Bangla tokens**.  \n- ‚ö†Ô∏è Validation plateau is expected due to **novel language and dataset size**.  \n- üõ°Ô∏è Early stopping ensures the model does not overfit. Overall, the model **successfully adapts T5 to Bangla** with custom tokens and mixed-language training.\n","metadata":{}},{"cell_type":"markdown","source":"### üß∞ Zip to download best model","metadata":{}},{"cell_type":"code","source":"#Zip the best Model\n%cd /kaggle/working\n!zip -r t5_bangla_english_custom_model.zip t5_custom_model new_custom_tokens.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T20:22:28.428430Z","iopub.execute_input":"2025-08-25T20:22:28.428737Z","iopub.status.idle":"2025-08-25T20:22:43.671835Z","shell.execute_reply.started":"2025-08-25T20:22:28.428712Z","shell.execute_reply":"2025-08-25T20:22:43.670950Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n  adding: t5_custom_model/ (stored 0%)\n  adding: t5_custom_model/tokenizer_config.json (deflated 95%)\n  adding: t5_custom_model/config.json (deflated 63%)\n  adding: t5_custom_model/special_tokens_map.json (deflated 85%)\n  adding: t5_custom_model/added_tokens.json (deflated 72%)\n  adding: t5_custom_model/generation_config.json (deflated 29%)\n  adding: t5_custom_model/model.safetensors (deflated 7%)\n  adding: t5_custom_model/spiece.model (deflated 48%)\n  adding: new_custom_tokens.txt (deflated 64%)\n","output_type":"stream"}],"execution_count":72},{"cell_type":"markdown","source":"#### ‚ö° Checking Model Parameters","metadata":{}},{"cell_type":"code","source":"# Checking Model Parameters (example float32/float16)\nfor name, param in model.named_parameters():\n    print(f\"Parameter '{name}' has dtype: {param.dtype}\")\n    break # We only need to check the first one","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T20:23:10.041794Z","iopub.execute_input":"2025-08-25T20:23:10.042132Z","iopub.status.idle":"2025-08-25T20:23:10.047592Z","shell.execute_reply.started":"2025-08-25T20:23:10.042103Z","shell.execute_reply":"2025-08-25T20:23:10.046858Z"}},"outputs":[{"name":"stdout","text":"Parameter 'shared.weight' has dtype: torch.float32\n","output_type":"stream"}],"execution_count":73},{"cell_type":"markdown","source":"# üìä Model Evaluation (BLEU, ROUGE, Log-Likelihood)","metadata":{}},{"cell_type":"code","source":"example = \"‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡ßá‡¶Æ‡¶® ‡¶Ü‡¶õ‡ßá‡¶®?\"  # Bangla input\ninputs = tokenizer(example, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n\nwith torch.no_grad():\n    generated_ids = model.generate(\n        **inputs,\n        max_length=128,\n        num_beams=4,    # beam search for better translation\n        early_stopping=True\n    )\nprint(f\"Text: {example}\")\ntranslation = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\nprint(\"Translation:\", translation)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T20:23:18.405651Z","iopub.execute_input":"2025-08-25T20:23:18.405942Z","iopub.status.idle":"2025-08-25T20:23:19.443398Z","shell.execute_reply.started":"2025-08-25T20:23:18.405918Z","shell.execute_reply":"2025-08-25T20:23:19.442735Z"}},"outputs":[{"name":"stdout","text":"Text: ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡ßá‡¶Æ‡¶® ‡¶Ü‡¶õ‡ßá‡¶®?\nTranslation: How are yo u t oda y? I wa s yo u are yo u h ave yo u. Your p res e nt?\n","output_type":"stream"}],"execution_count":74},{"cell_type":"markdown","source":"# üß™ Test / Unseen Dataset","metadata":{}},{"cell_type":"code","source":"# === Unseen Dataset ===\nunseen_dataset = pd.read_csv(\"/kaggle/input/bangla-english-custom-dataset/final-datasets/test-data.csv\")\nprint(\"=================About Unseen Dataset======================\")\nprint(f\"shape of dataset: {unseen_dataset.shape}\")\nunseen_dataset.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T20:23:35.023799Z","iopub.execute_input":"2025-08-25T20:23:35.024086Z","iopub.status.idle":"2025-08-25T20:23:35.056947Z","shell.execute_reply.started":"2025-08-25T20:23:35.024064Z","shell.execute_reply":"2025-08-25T20:23:35.056398Z"}},"outputs":[{"name":"stdout","text":"=================About Unseen Dataset======================\nshape of dataset: (167, 2)\n","output_type":"stream"},{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"                                                Text  \\\n0  ‡¶∂‡ßÅ‡¶≠ ‡¶®‡¶¨‡¶¨‡¶∞‡ßç‡¶∑! ‡¶™‡¶π‡ßá‡¶≤‡¶æ ‡¶¨‡ßà‡¶∂‡¶æ‡¶ñ‡ßá ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡¶ø ‡¶®‡¶§‡ßÅ‡¶® ‡¶ú‡¶æ‡¶Æ‡¶æ ‡¶™‡¶∞‡ßá...   \n1  ‡¶ú‡¶®‡ßç‡¶Æ‡¶¶‡¶ø‡¶®‡ßá‡¶∞ ‡¶∂‡ßÅ‡¶≠‡ßá‡¶ö‡ßç‡¶õ‡¶æ! ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡¶ø ‡¶ú‡¶®‡ßç‡¶Æ‡¶¶‡¶ø‡¶®‡ßá ‡¶ï‡ßá‡¶ï ‡¶ï‡¶æ‡¶ü‡¶¨‡ßá...   \n2  ‡¶∂‡ßÅ‡¶≠ ‡¶∞‡¶¨‡ßÄ‡¶®‡ßç‡¶¶‡ßç‡¶∞ ‡¶ú‡¶Ø‡¶º‡¶®‡ßç‡¶§‡ßÄ! ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡¶ø ‡¶∞‡¶¨‡ßÄ‡¶®‡ßç‡¶¶‡ßç‡¶∞‡¶®‡¶æ‡¶•‡ßá‡¶∞ ‡¶ó‡¶æ...   \n3  ‡¶™‡¶π‡ßá‡¶≤‡¶æ ‡¶´‡¶æ‡¶≤‡ßç‡¶ó‡ßÅ‡¶®‡ßá‡¶∞ ‡¶∂‡ßÅ‡¶≠‡ßá‡¶ö‡ßç‡¶õ‡¶æ! ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡¶ø ‡¶´‡ßÅ‡¶≤‡ßá‡¶∞ ‡¶ú‡¶æ‡¶Æ‡¶æ ‡¶™...   \n4  ‡¶≠‡¶æ‡¶≤‡ßã‡¶¨‡¶æ‡¶∏‡¶æ ‡¶¶‡¶ø‡¶¨‡¶∏‡ßá‡¶∞ ‡¶∂‡ßÅ‡¶≠‡¶ï‡¶æ‡¶Æ‡¶®‡¶æ! ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡¶ø ‡¶™‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶ú‡¶®‡ßá‡¶∞ ‡¶∏...   \n\n                                              Target  \n0  Happy New Year! Rocking a new outfit for Pohel...  \n1  Happy Birthday! Cutting a cake for your birthd...  \n2  Happy Rabindra Jayanti! Singing Tagore‚Äôs songs...  \n3  Happy Pohela Falgun! Wearing a floral outfit? ...  \n4  Happy Valentine‚Äôs Day! Planning a dinner with ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>‡¶∂‡ßÅ‡¶≠ ‡¶®‡¶¨‡¶¨‡¶∞‡ßç‡¶∑! ‡¶™‡¶π‡ßá‡¶≤‡¶æ ‡¶¨‡ßà‡¶∂‡¶æ‡¶ñ‡ßá ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡¶ø ‡¶®‡¶§‡ßÅ‡¶® ‡¶ú‡¶æ‡¶Æ‡¶æ ‡¶™‡¶∞‡ßá...</td>\n      <td>Happy New Year! Rocking a new outfit for Pohel...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>‡¶ú‡¶®‡ßç‡¶Æ‡¶¶‡¶ø‡¶®‡ßá‡¶∞ ‡¶∂‡ßÅ‡¶≠‡ßá‡¶ö‡ßç‡¶õ‡¶æ! ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡¶ø ‡¶ú‡¶®‡ßç‡¶Æ‡¶¶‡¶ø‡¶®‡ßá ‡¶ï‡ßá‡¶ï ‡¶ï‡¶æ‡¶ü‡¶¨‡ßá...</td>\n      <td>Happy Birthday! Cutting a cake for your birthd...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>‡¶∂‡ßÅ‡¶≠ ‡¶∞‡¶¨‡ßÄ‡¶®‡ßç‡¶¶‡ßç‡¶∞ ‡¶ú‡¶Ø‡¶º‡¶®‡ßç‡¶§‡ßÄ! ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡¶ø ‡¶∞‡¶¨‡ßÄ‡¶®‡ßç‡¶¶‡ßç‡¶∞‡¶®‡¶æ‡¶•‡ßá‡¶∞ ‡¶ó‡¶æ...</td>\n      <td>Happy Rabindra Jayanti! Singing Tagore‚Äôs songs...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>‡¶™‡¶π‡ßá‡¶≤‡¶æ ‡¶´‡¶æ‡¶≤‡ßç‡¶ó‡ßÅ‡¶®‡ßá‡¶∞ ‡¶∂‡ßÅ‡¶≠‡ßá‡¶ö‡ßç‡¶õ‡¶æ! ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡¶ø ‡¶´‡ßÅ‡¶≤‡ßá‡¶∞ ‡¶ú‡¶æ‡¶Æ‡¶æ ‡¶™...</td>\n      <td>Happy Pohela Falgun! Wearing a floral outfit? ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>‡¶≠‡¶æ‡¶≤‡ßã‡¶¨‡¶æ‡¶∏‡¶æ ‡¶¶‡¶ø‡¶¨‡¶∏‡ßá‡¶∞ ‡¶∂‡ßÅ‡¶≠‡¶ï‡¶æ‡¶Æ‡¶®‡¶æ! ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡¶ø ‡¶™‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶ú‡¶®‡ßá‡¶∞ ‡¶∏...</td>\n      <td>Happy Valentine‚Äôs Day! Planning a dinner with ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":75},{"cell_type":"markdown","source":"| #  | Name / Type           | Short Code Summary / Purpose                                                                 |\n|----|----------------------|---------------------------------------------------------------------------------------------|\n| 1Ô∏è‚É£ | `evaluate_model`      | Function: Evaluates a trained model on BLEU, ROUGE-1, ROUGE-L, Perplexity, and Log-Likelihood metrics. |\n| 2Ô∏è‚É£ | `model.eval()`        | Puts model in evaluation mode; disables dropout and gradient updates.                      |\n| 3Ô∏è‚É£ | `bleu_metric = load(\"sacrebleu\")` | Initializes BLEU metric from `datasets` library for translation quality evaluation.       |\n| 4Ô∏è‚É£ | `rouge_metric = load(\"rouge\")`   | Initializes ROUGE metric for summarization/sequence comparison.                           |\n| 5Ô∏è‚É£ | Tokenization          | Converts `text_input` and `english_targets` into tensors with padding/truncation for batching. |\n| 6Ô∏è‚É£ | Prediction Generation | Uses `model.generate` with `num_beams=4`, `max_length=128` for beam search decoding.       |\n| 7Ô∏è‚É£ | Decoding Predictions  | Converts generated token IDs back to text using `tokenizer.batch_decode`.                  |\n| 8Ô∏è‚É£ | Perplexity / NLL      | Computes average negative log-likelihood and perplexity per token for model confidence.    |\n| 9Ô∏è‚É£ | Metric Computation    | Computes BLEU score, ROUGE scores, log-likelihood, and perplexity from predictions & references. |\n| üîü | Batching              | Processes data in batches (size=8) for memory efficiency on GPU/CPU.                       |\n| 1Ô∏è‚É£ | Return Dictionary    | Returns a dictionary containing: `log_likelihood`, `perplexity`, `bleu`, and `rouge` scores. |\n","metadata":{}},{"cell_type":"markdown","source":"| Name / Metric        | Why We Use It                                  | What It Does / How It Works                                           | Typical Performance Range / Value |\n|---------------------|-----------------------------------------------|-----------------------------------------------------------------------|----------------------------------|\n| Perplexity / NLL üî•  | Measure model confidence & fluency            | Computes average negative log-likelihood per token; lower = better   | 10‚Äì50 for well-trained translation; lower is better |\n| BLEU üìä              | Evaluate translation quality                  | Compares n-gram overlap between generated text & reference; higher = better | 0‚Äì100; >30 considered reasonable for small datasets; >50 strong |\n| ROUGE-1 / ROUGE-L üìù | Evaluate content & sequence similarity        | ROUGE-1: unigram overlap; ROUGE-L: longest common subsequence; higher = better | 0‚Äì100; >40‚Äì50 decent for translation/summarization; >60 good |\n","metadata":{}},{"cell_type":"code","source":"# ----------------------------------------------------------------------------\n# 1Ô∏è‚É£ Model Evaluation with BLEU, ROUGE-1, ROUGE-L, PERPLEXITY, and Log-Likelihood\n# ----------------------------------------------------------------------------\ndef evaluate_model(model, tokenizer, text_input, english_targets, device):\n    \"\"\"\n    Evaluates a model on BLEU, ROUGE, Perplexity, and Log-Likelihood.\n\n    Args:\n        model (torch.nn.Module): The trained language model.\n        tokenizer: The tokenizer for the model.\n        text_input (list of str): The source sentences.\n        english_targets (list of str): The reference target sentences.\n        device (torch.device): The device (e.g., 'cuda' or 'cpu').\n\n    Returns:\n        dict: A dictionary containing the computed metrics.\n    \"\"\"\n    model.eval()\n    \n    # Initialize metrics\n    bleu_metric = load(\"sacrebleu\")\n    rouge_metric = load(\"rouge\")\n    \n    predictions = []\n    total_val_loss = 0.0\n    total_tokens = 0\n    \n    # Tokenize the entire dataset at once for efficiency\n    tokenized_inputs = tokenizer(text_input, return_tensors='pt', padding=True, truncation=True)\n    tokenized_targets = tokenizer(english_targets, return_tensors='pt', padding=True, truncation=True)\n    \n    with torch.no_grad():\n        # --- Generate Predictions for BLEU & ROUGE ---\n        # We process the data in batches for memory efficiency\n        for i in tqdm(range(0, len(text_input), 8), desc=\"Generating Predictions\"):\n            batch_inputs = {key: tensor[i:i+8].to(device) for key, tensor in tokenized_inputs.items()}\n            \n            generated_ids = model.generate(\n                **batch_inputs,\n                max_length=128,\n                num_beams=4,\n                early_stopping=True,\n            )\n            decoded_preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n            predictions.extend(decoded_preds)\n\n        # --- Calculate Perplexity & Log-Likelihood ---\n        for i in tqdm(range(0, len(text_input), 8), desc=\"Calculating Perplexity\"):\n            batch_inputs = {key: tensor[i:i+8].to(device) for key, tensor in tokenized_inputs.items()}\n            batch_labels = tokenized_targets['input_ids'][i:i+8].to(device)\n            \n            outputs = model(**batch_inputs, labels=batch_labels)\n            \n            num_tokens = batch_labels.ne(tokenizer.pad_token_id).sum().item()\n            total_val_loss += outputs.loss.item() * num_tokens\n            total_tokens += num_tokens\n\n    # --- Final Metric Computation ---\n    avg_nll = total_val_loss / total_tokens\n    perplexity = np.exp(avg_nll)\n    \n    formatted_references = [[ref] for ref in english_targets]\n    bleu_score = bleu_metric.compute(predictions=predictions, references=formatted_references)['score']\n    \n    rouge_scores = rouge_metric.compute(predictions=predictions, references=english_targets)\n    \n    return {\n        \"log_likelihood\": -avg_nll,\n        \"perplexity\": perplexity,\n        \"bleu\": bleu_score,\n        \"rouge\": rouge_scores\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T20:28:56.299779Z","iopub.execute_input":"2025-08-25T20:28:56.300513Z","iopub.status.idle":"2025-08-25T20:28:56.309170Z","shell.execute_reply.started":"2025-08-25T20:28:56.300490Z","shell.execute_reply":"2025-08-25T20:28:56.308380Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"# Run the evaluation\n\ntext_input = unseen_dataset['Text'].tolist()\nenglish_targets = unseen_dataset['Target'].tolist()\n\nmetrics = evaluate_model(model, tokenizer, text_input, english_targets, device)\n    \n# Print the results\nprint(\"\\n--- Evaluation Results ---\")\nprint(f\"Log-Likelihood (avg): {metrics['log_likelihood']:.4f}\")\nprint(f\"Perplexity: {metrics['perplexity']:.2f}\")\nprint(f\"BLEU Score: {metrics['bleu']:.2f}\")\nprint(\"ROUGE Scores:\")\nfor key, value in metrics['rouge'].items():\n    print(f\"  - {key}: {value:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T20:29:05.128252Z","iopub.execute_input":"2025-08-25T20:29:05.128804Z","iopub.status.idle":"2025-08-25T20:29:35.737657Z","shell.execute_reply.started":"2025-08-25T20:29:05.128778Z","shell.execute_reply":"2025-08-25T20:29:35.737014Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"796e2f59f5114a4a8cc29181c8c514ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b0888be545c4a3a9488a0d7ea53c8f6"}},"metadata":{}},{"name":"stderr","text":"Generating Predictions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21/21 [00:27<00:00,  1.32s/it]\nCalculating Perplexity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21/21 [00:01<00:00, 18.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n--- Evaluation Results ---\nLog-Likelihood (avg): -5.2099\nPerplexity: 183.08\nBLEU Score: 1.76\nROUGE Scores:\n  - rouge1: 0.1319\n  - rouge2: 0.0208\n  - rougeL: 0.1178\n  - rougeLsum: 0.1183\n","output_type":"stream"}],"execution_count":78},{"cell_type":"markdown","source":"| Metric                  | Value      | Purpose / Why We Use It                                | Interpretation / Justification                                      |\n|-------------------------|-----------|-------------------------------------------------------|---------------------------------------------------------------------|\n| Log-Likelihood (NLL) üî•  | -5.2099   | Measures model‚Äôs confidence in predicting tokens      | Negative value expected; shows model predicts tokens reasonably, but still uncertain on new Bangla patterns |\n| Perplexity üéØ            | 183.08    | Measures prediction uncertainty; lower = better      | High perplexity indicates Bangla is still challenging for T5, due to limited exposure and dataset size |\n| BLEU üìä                  | 1.76      | Measures n-gram overlap with reference translation   | Very low BLEU reflects difficulty in exact Bangla-English translation; expected for first adaptation |\n| ROUGE-1 üìù               | 0.1319    | Measures unigram overlap / content coverage          | Low overlap shows generated text partially matches references; model starting to learn Bangla |\n| ROUGE-2 üìù               | 0.0208    | Measures bigram overlap / phrase similarity          | Very low score indicates limited phrase-level accuracy; expected with small dataset |\n| ROUGE-L / ROUGE-Lsum üìù  | 0.1178 / 0.1183 | Measures longest common subsequence / overall structure | Confirms partial structural learning; model captures some word order but still limited |\n","metadata":{}},{"cell_type":"markdown","source":"# üß† Predicting Sentence and Evaluation Table","metadata":{}},{"cell_type":"code","source":"# ----------------------------------------------------------------------------\n# 1Ô∏è‚É£ Model Evaluation Table 10 Sentences for ROUGE and Log-Likelihood\n# ----------------------------------------------------------------------------\n\ndef evaluate_and_generate_table(model, tokenizer, df, iloc_indices, device):\n    \"\"\"\n    Evaluates a model on selected rows and generates a table with scores.\n    \n    Args:\n        model (torch.nn.Module): The trained language model.\n        tokenizer: The tokenizer for the model.\n        df (pd.DataFrame): The full validation dataset.\n        iloc_indices (list of int): A list of integer indices to select rows.\n        device (torch.device): The device (e.g., 'cuda' or 'cpu').\n        \n    Returns:\n        pd.DataFrame: A DataFrame with input, target, prediction, and scores.\n        dict: A dictionary of overall corpus-level scores.\n    \"\"\"\n    model.eval()\n\n    # Select the rows based on iloc_indices\n    selected_df = df.iloc[iloc_indices].copy()\n    \n    text_input = selected_df['Text'].tolist()\n    english_targets = selected_df['Target'].tolist()\n    \n    # Initialize metric loaders\n    rouge_metric = load(\"rouge\")\n    bleu_metric = load(\"sacrebleu\")\n    \n    # Lists to store results\n    predictions = []\n    sentence_rouge_l_scores = []\n    sentence_log_likelihoods = []\n    \n    total_val_loss = 0.0\n    total_tokens = 0\n    \n    with torch.no_grad():\n        for i in range(len(text_input)):\n            input_text = text_input[i]\n            target_text = english_targets[i]\n\n            # Tokenize individual sentence\n            tokenized_input = tokenizer(input_text, return_tensors='pt', truncation=True).to(device)\n            tokenized_target = tokenizer(target_text, return_tensors='pt', truncation=True).to(device)\n\n            # --- Generate Prediction for this sentence ---\n            generated_ids = model.generate(\n                **tokenized_input,\n                max_length=128,\n                num_beams=4,\n                early_stopping=True,\n            )\n            decoded_pred = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n            predictions.append(decoded_pred)\n            \n            # --- Calculate Sentence-level ROUGE-L Score ---\n            rouge_score = rouge_metric.compute(predictions=[decoded_pred], references=[target_text])\n            sentence_rouge_l_scores.append(rouge_score['rougeL'])\n\n            # --- Calculate Sentence-level Log-Likelihood ---\n            outputs = model(**tokenized_input, labels=tokenized_target['input_ids'])\n            \n            num_tokens = tokenized_target['attention_mask'].sum().item()\n            sentence_nll = outputs.loss.item() * num_tokens\n            sentence_log_likelihoods.append(-sentence_nll)\n\n            # Accumulate for corpus-level scores\n            total_val_loss += outputs.loss.item() * num_tokens\n            total_tokens += num_tokens\n\n    # Add new columns to the DataFrame\n    selected_df['Predicted'] = predictions\n    selected_df['ROUGE-L Score'] = sentence_rouge_l_scores\n    selected_df['Log-Likelihood'] = sentence_log_likelihoods\n    \n    # --- Calculate Corpus-level Scores for the entire selected subset ---\n    avg_nll = total_val_loss / total_tokens\n    perplexity = np.exp(avg_nll)\n    \n    bleu_score = bleu_metric.compute(\n        predictions=predictions, \n        references=[[ref] for ref in english_targets]\n    )['score']\n    \n    corpus_scores = {\n        \"Overall BLEU Score\": bleu_score,\n        \"Overall Perplexity\": perplexity\n    }\n    \n    return selected_df, corpus_scores\n\n\n    \n# Choose your 10 indexes\nselected_indices = [0, 1, 10, 57, 58, 60, 112, 114, 118, 11] \n\n# Generate the table and get overall scores\nresults_df, corpus_scores = evaluate_and_generate_table(model, tokenizer, unseen_dataset, selected_indices, device)\n\nprint(\"\\n--- Overall Corpus Scores for the 10 Selected Sentences ---\")\nprint(f\"Overall BLEU Score: {corpus_scores['Overall BLEU Score']:.2f}\")\nprint(f\"Overall Perplexity: {corpus_scores['Overall Perplexity']:.2f}\")\n\n\nprint(\"--- Sentence-Level Results Table ---\")\nresults_df[['Text', 'Target', 'Predicted', 'ROUGE-L Score', 'Log-Likelihood']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T20:31:33.849636Z","iopub.execute_input":"2025-08-25T20:31:33.850026Z","iopub.status.idle":"2025-08-25T20:31:46.417761Z","shell.execute_reply.started":"2025-08-25T20:31:33.850004Z","shell.execute_reply":"2025-08-25T20:31:46.417158Z"}},"outputs":[{"name":"stdout","text":"\n--- Overall Corpus Scores for the 10 Selected Sentences ---\nOverall BLEU Score: 1.51\nOverall Perplexity: 6.64\n--- Sentence-Level Results Table ---\n","output_type":"stream"},{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"                                                  Text  \\\n0    ‡¶∂‡ßÅ‡¶≠ ‡¶®‡¶¨‡¶¨‡¶∞‡ßç‡¶∑! ‡¶™‡¶π‡ßá‡¶≤‡¶æ ‡¶¨‡ßà‡¶∂‡¶æ‡¶ñ‡ßá ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡¶ø ‡¶®‡¶§‡ßÅ‡¶® ‡¶ú‡¶æ‡¶Æ‡¶æ ‡¶™‡¶∞‡ßá...   \n1    ‡¶ú‡¶®‡ßç‡¶Æ‡¶¶‡¶ø‡¶®‡ßá‡¶∞ ‡¶∂‡ßÅ‡¶≠‡ßá‡¶ö‡ßç‡¶õ‡¶æ! ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡¶ø ‡¶ú‡¶®‡ßç‡¶Æ‡¶¶‡¶ø‡¶®‡ßá ‡¶ï‡ßá‡¶ï ‡¶ï‡¶æ‡¶ü‡¶¨‡ßá...   \n10   ‡¶¨‡¶æ‡¶∏‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶¶‡ßá‡¶ñ‡ßÅ‡¶®! ‡¶¨‡¶æ‡¶∏ ‡¶∏‡ßç‡¶ü‡¶™‡ßá ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡¶ø ‡¶Ö‡¶™‡ßá‡¶ï‡ßç‡¶∑‡¶æ‡¶Ø‡¶º ...   \n57   Apni ajke amar sathe cholben hospital e? Docto...   \n58   Apni ki shunechhen kalke brishti hobe? If it r...   \n60   Apni kemon achen? Ajke office theke ashte deri...   \n112  ‡¶Ü‡¶ú‡¶ï‡ßá weather ‡¶ü‡¶æ ‡¶è‡¶§ hot ‡¶õ‡¶ø‡¶≤ ‡¶Ø‡ßá ‡¶¨‡¶æ‡¶á‡¶∞‡ßá ‡ßß‡ß¶ ‡¶Æ‡¶ø‡¶®‡¶ø‡¶ü ‡¶¶...   \n114  ‡¶Ü‡¶™‡¶®‡¶ø ‡¶Ø‡¶¶‡¶ø documents ‡¶ó‡ßÅ‡¶≤‡ßã ‡¶Ü‡¶ó‡ßá check ‡¶ï‡¶∞‡¶§‡ßá‡¶®, ‡¶§‡¶æ‡¶π‡¶≤‡ßá...   \n118  ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡¶ø ‡¶Ü‡¶ú‡¶ï‡ßá evening ‡¶è free ‡¶•‡¶æ‡¶ï‡¶¨‡ßá‡¶®? ‡¶Ø‡¶¶‡¶ø ‡¶•‡¶æ‡¶ï‡ßá‡¶®,...   \n11   ‡¶∞‡¶ø‡¶ï‡¶∂‡¶æ ‡¶®‡¶ø‡¶®! ‡¶Ö‡¶´‡¶ø‡¶∏‡ßá ‡¶¶‡ßá‡¶∞‡¶ø ‡¶π‡¶ö‡ßç‡¶õ‡ßá, ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡¶ø ‡¶∞‡¶ø‡¶ï‡¶∂‡¶æ ‡¶ß‡¶∞‡¶¨...   \n\n                                                Target  \\\n0    Happy New Year! Rocking a new outfit for Pohel...   \n1    Happy Birthday! Cutting a cake for your birthd...   \n10   Check the bus time! Exhausted waiting at the b...   \n57   Will you come with me to the hospital today? T...   \n58   Have you heard it will rain tomorrow? If it ra...   \n60   How are you? Today I was late coming from the ...   \n112  Today the weather was so hot that even standin...   \n114  If you had checked the documents earlier, the ...   \n118  Will you be free this evening? If yes, then we...   \n11   Take a rickshaw! Late for work, grabbing a ric...   \n\n                                             Predicted  ROUGE-L Score  \\\n0    Ha ppy N ew Year! Rocking a ne w c lothes at t...       0.185567   \n1    Ha ppy B ir th da y! Cut ti ng c ake w ith f r...       0.060606   \n10   Ca tch the bus! Swea ti ng at the bus st op? K...       0.253521   \n57   Wi ll yo u h ave a do c tor t oda y? I wa s th...       0.080000   \n58   Wi ll yo u h ave lu nch at the o ff ice t oda ...       0.064516   \n60   T oda y I wo nde rin g w ith yo u were a lo t ...       0.029412   \n112  T oda y I we nt to a t ra ff ic jam for a wa l...       0.096774   \n114  I h ave a p ro j ect de ad lin e! P ro j ect d...       0.026667   \n118  Wi ll yo u go to the park t oda y? I wa s thin...       0.103448   \n11   G et a ri cks h aw! La te for wo rk? S tuck in...       0.123077   \n\n     Log-Likelihood  \n0        -65.834574  \n1       -120.076232  \n10      -147.567186  \n57      -115.706002  \n58      -173.323252  \n60      -119.880291  \n112     -239.615145  \n114     -166.484354  \n118      -93.955496  \n11       -80.956211  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Target</th>\n      <th>Predicted</th>\n      <th>ROUGE-L Score</th>\n      <th>Log-Likelihood</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>‡¶∂‡ßÅ‡¶≠ ‡¶®‡¶¨‡¶¨‡¶∞‡ßç‡¶∑! ‡¶™‡¶π‡ßá‡¶≤‡¶æ ‡¶¨‡ßà‡¶∂‡¶æ‡¶ñ‡ßá ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡¶ø ‡¶®‡¶§‡ßÅ‡¶® ‡¶ú‡¶æ‡¶Æ‡¶æ ‡¶™‡¶∞‡ßá...</td>\n      <td>Happy New Year! Rocking a new outfit for Pohel...</td>\n      <td>Ha ppy N ew Year! Rocking a ne w c lothes at t...</td>\n      <td>0.185567</td>\n      <td>-65.834574</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>‡¶ú‡¶®‡ßç‡¶Æ‡¶¶‡¶ø‡¶®‡ßá‡¶∞ ‡¶∂‡ßÅ‡¶≠‡ßá‡¶ö‡ßç‡¶õ‡¶æ! ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡¶ø ‡¶ú‡¶®‡ßç‡¶Æ‡¶¶‡¶ø‡¶®‡ßá ‡¶ï‡ßá‡¶ï ‡¶ï‡¶æ‡¶ü‡¶¨‡ßá...</td>\n      <td>Happy Birthday! Cutting a cake for your birthd...</td>\n      <td>Ha ppy B ir th da y! Cut ti ng c ake w ith f r...</td>\n      <td>0.060606</td>\n      <td>-120.076232</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>‡¶¨‡¶æ‡¶∏‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶¶‡ßá‡¶ñ‡ßÅ‡¶®! ‡¶¨‡¶æ‡¶∏ ‡¶∏‡ßç‡¶ü‡¶™‡ßá ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡¶ø ‡¶Ö‡¶™‡ßá‡¶ï‡ßç‡¶∑‡¶æ‡¶Ø‡¶º ...</td>\n      <td>Check the bus time! Exhausted waiting at the b...</td>\n      <td>Ca tch the bus! Swea ti ng at the bus st op? K...</td>\n      <td>0.253521</td>\n      <td>-147.567186</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>Apni ajke amar sathe cholben hospital e? Docto...</td>\n      <td>Will you come with me to the hospital today? T...</td>\n      <td>Wi ll yo u h ave a do c tor t oda y? I wa s th...</td>\n      <td>0.080000</td>\n      <td>-115.706002</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>Apni ki shunechhen kalke brishti hobe? If it r...</td>\n      <td>Have you heard it will rain tomorrow? If it ra...</td>\n      <td>Wi ll yo u h ave lu nch at the o ff ice t oda ...</td>\n      <td>0.064516</td>\n      <td>-173.323252</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>Apni kemon achen? Ajke office theke ashte deri...</td>\n      <td>How are you? Today I was late coming from the ...</td>\n      <td>T oda y I wo nde rin g w ith yo u were a lo t ...</td>\n      <td>0.029412</td>\n      <td>-119.880291</td>\n    </tr>\n    <tr>\n      <th>112</th>\n      <td>‡¶Ü‡¶ú‡¶ï‡ßá weather ‡¶ü‡¶æ ‡¶è‡¶§ hot ‡¶õ‡¶ø‡¶≤ ‡¶Ø‡ßá ‡¶¨‡¶æ‡¶á‡¶∞‡ßá ‡ßß‡ß¶ ‡¶Æ‡¶ø‡¶®‡¶ø‡¶ü ‡¶¶...</td>\n      <td>Today the weather was so hot that even standin...</td>\n      <td>T oda y I we nt to a t ra ff ic jam for a wa l...</td>\n      <td>0.096774</td>\n      <td>-239.615145</td>\n    </tr>\n    <tr>\n      <th>114</th>\n      <td>‡¶Ü‡¶™‡¶®‡¶ø ‡¶Ø‡¶¶‡¶ø documents ‡¶ó‡ßÅ‡¶≤‡ßã ‡¶Ü‡¶ó‡ßá check ‡¶ï‡¶∞‡¶§‡ßá‡¶®, ‡¶§‡¶æ‡¶π‡¶≤‡ßá...</td>\n      <td>If you had checked the documents earlier, the ...</td>\n      <td>I h ave a p ro j ect de ad lin e! P ro j ect d...</td>\n      <td>0.026667</td>\n      <td>-166.484354</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡¶ø ‡¶Ü‡¶ú‡¶ï‡ßá evening ‡¶è free ‡¶•‡¶æ‡¶ï‡¶¨‡ßá‡¶®? ‡¶Ø‡¶¶‡¶ø ‡¶•‡¶æ‡¶ï‡ßá‡¶®,...</td>\n      <td>Will you be free this evening? If yes, then we...</td>\n      <td>Wi ll yo u go to the park t oda y? I wa s thin...</td>\n      <td>0.103448</td>\n      <td>-93.955496</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>‡¶∞‡¶ø‡¶ï‡¶∂‡¶æ ‡¶®‡¶ø‡¶®! ‡¶Ö‡¶´‡¶ø‡¶∏‡ßá ‡¶¶‡ßá‡¶∞‡¶ø ‡¶π‡¶ö‡ßç‡¶õ‡ßá, ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡¶ø ‡¶∞‡¶ø‡¶ï‡¶∂‡¶æ ‡¶ß‡¶∞‡¶¨...</td>\n      <td>Take a rickshaw! Late for work, grabbing a ric...</td>\n      <td>G et a ri cks h aw! La te for wo rk? S tuck in...</td>\n      <td>0.123077</td>\n      <td>-80.956211</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":79},{"cell_type":"markdown","source":"### Justification ‚Äì ROUGE-L & Log-Likelihood\n\n| #   | ROUGE-L Score | Log-Likelihood | Justification |\n|-----|---------------|----------------|---------------|\n| 0   | 0.1856        | -65.8346       | Moderate overlap with reference; model reasonably predicts festive greeting. |\n| 1   | 0.0606        | -120.0762      | Low overlap; birthday sentence structure differs from model output, higher NLL indicates uncertainty. |\n| 10  | 0.2535        | -147.5672      | Higher ROUGE-L shows partial correct sequence; negative log-likelihood high due to token errors. |\n| 57  | 0.0800        | -115.7060      | Small overlap; model struggles with question structure; NLL indicates prediction uncertainty. |\n| 58  | 0.0645        | -173.3233      | Very low overlap; model fails to capture future tense; high NLL reflects poor token probability. |\n| 60  | 0.0294        | -119.8803      | Minimal overlap; conversational tone not well captured, moderate NLL. |\n| 112 | 0.0968        | -239.6151      | Low overlap for long mixed Bangla-English sentence; very high NLL due to complexity. |\n| 114 | 0.0267        | -166.4844      | Almost no overlap; document-related context not learned; high NLL. |\n| 118 | 0.1034        | -93.9555       | Slightly better overlap; model partially captures evening query, moderate NLL. |\n| 11  | 0.1231        | -80.9562       | Fair ROUGE-L; rickshaw request partially understood, lower NLL reflects simpler tokens. |\n","metadata":{}}]}